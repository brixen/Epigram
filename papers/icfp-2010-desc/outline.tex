\documentclass{article}

\usepackage{verbatim}
\usepackage{fullpage}

%% Structure
\newenvironment{structure}{\footnotesize\verbatim}{\endverbatim}
%\newenvironment{structure}{\comment}{\endcomment}


\begin{document}

\section{The Type Theory}

\subsection{Base theory}

\begin{structure}
<- Presentation of the formalism
    <- Standard presentation
        -> No novelty here
    <- 3 judgments [equation]
        -> Context validity
        -> Typing judgements
        -> Equality judgements
    <- Invariants [equation]
        -> By induction on derivations
    <- Judgemental equality
        <- Presentation independant of particular implementation choice
        -> Model in Agda, intensional
        -> Used in Epigram, OTT
\end{structure}

\begin{structure}
<- Context validity [figure]
    <- Not much to be said
\end{structure}

\begin{structure}
<- Typing judgements [figure]
    <- Set in Set
        -> For simplicity of presentation
        -> Assume that a valid stratification can be inferred
            <- Implicit syntax, Pollack (?, or better reference)
        -> See later discussion
    <- Standard presentation of Pi and Sigma types
\end{structure}

\begin{structure}
<- Judgemental equality [figure]
    <- symmetry, reflexivity, and transitivity
    <- beta-rules for lambda and pair
    <- xi-rule for functions
    /> Assume transitivity, reflexity, and symmetry
    -> Agnostic in the notion of equality
        <- Doesn't rely on a ``propositional'' equality
\end{structure}

\begin{structure}
!!! Need Help !!!
<- Meta-theoretical properties
    <- Assuming a stratified discipline
        <- Harper-Pollack, Luo, Courant
    <> The point here is to reassert that dependent types are not evil, 
       there is no non-terminating type-checker, or such horrible lies <>
    -> Strongly normalizing
        -> Every program terminates
    -> Type-checking terminates
    ???
\end{structure}

\subsection{Finite sets}

\begin{structure}
<- Motivation
    <- Finite sets could be encoded with Unit and Bool
        /> Hinder the ability to name things
    -> For convenience
        <- Named elements
        <- Referring by name instead of code
        -> Types as coding presentation
            /> Also as coding representation!
\end{structure}

\begin{structure}
<- Implementation
    <- Tags
        -> Purely informational token
    <- EnumU
        -> Universe of finite sets
    <- EnumT e
        -> Elements of finite set e
\end{structure}

\begin{structure}
<- Equipment
    <- \spi operator
        <- Equivalent of Pi on finite sets
        <- First argument: (finite) domain
        <- Second argument: for each element of the domain, a co-domain
        -> Inhabitant of \spi: right-nested tuple of solutions
            <- Skip code for space reasons
    <- switch operator
        <- case analyses over x
        <- index into the \spi tuple to retrieve the corresponding result
\end{structure}

\begin{structure}
<- Equivalent to having a function space over finite sets
    /> Made non-obvious by low-level encodings
        <- General issue with codes
             -> Need to provide an attractive presentation to the user
    -> Types seem to obfuscate our reading
        <- Provide ``too much'' information
        /> False impression: information is actually waiting to be used more widely
        -> See next Section
\end{structure}

\subsection{Type propagation}

\begin{structure}
<- Bidirectional type-checking [ref. Turner,Pierce]
    -> Separating type-checking from type synthesis
    <- Type checking: push terms into types
        <- Example: |Pi S T :>: \ x . t| allows us to drop annotation on lambda
    <- Type inference: pull types out of terms
        <- Example: |x : S l- x :<: S| gives us the type of x
\end{structure}

\begin{structure}
<- Formalization: type propagation
    <- Motivation
        -> High-level syntax
            -> exprIn: types are pushed in
                <- Subject to type *checking*
            -> exprEx: types are pulled from
                <- Subject to type *synthesis*
        -> Translated into our low-level type theory
        -> Presented as judgements
    -> Presentation mirors typing rule of [figure] 
        -> Ignore identitical judgements
\end{structure}

\begin{structure}
<- Type checking [figure]
    <- Push a type in an exprIn
    <- Result in a full term
    -> *Use* the type to build the term!
        -> Domain and co-domain propagation for Pi and Sigma
        -> Translation of 'tags into EnumTs
        -> Translation of ['tags ...] into EnumUs
        -> Finite function space into switch
\end{structure}

\begin{structure}
<- Type synthesis [figure]
    <- Pull a type out of an exprEx
    <- Result in a full term, together with its type
    -> Do *not* need to specify types
        -> Extracting a term from the context
        -> Function application
        -> Projections
\end{structure}

\begin{structure}
<- Summary
    -> Not a novel technique [refs?]
        /> Used as a boilerplate scrapper
    -> Make dealing with codes *practical*
        <- Example: Finite sets/finite function space
        -> We should not restrain ourself in using codes
            <- We know how to present them to the user
-> Will extend this machinery in further sections
\end{structure}

\section{A universe of simple data-types}

\begin{structure}
<- Why starting with simple data-types
    <- For pedagogical purposes
        <- Data-types as we know them every day
        /> Target dependent types
    -> Cut down version of Induction Recursion
        -> Presentation evolves independently as we go to dependent types
\end{structure}

\subsection{The power of $\Sigma$}

\begin{structure}
<- The duality of Sigma
    <- Sigma generalizes sum over arbitrary arities
        -> \Sigma A B == \Sigma_{x : A} B x
    <- Sigma generalizes product to have a dependant second component
        -> \Sigma A B == (x : A) \times (B x)
\end{structure}

\begin{structure}
<- Data-types in the simply-typed world
    -> "sums-of-product"
        <- Sum of constructors
        <- Product of arguments
<- Data-types in the dependently-typed world
    -> "sigmas-of-sigmas"
    /> Need ability to manipulate these sigmas
        -> Define a Code for data-types
        -> Together with a sigma-based Interpretation
\end{structure}

\subsection{A universe of descriptions}

\begin{structure}
<- Introduction to Universe construction
    <- Define a Code
        -> Name objects
    <- Define an Interpretation of codes into the type theory
        -> Give a semantics to objects
    -> Ability to manipulate code
    -> Ability to compute with these objects
\end{structure}

\begin{structure}
<- Justification of the code 
    <- [both figures]: cannot be read separately
    <- Mimic the standard grammar of data-types description
        -> Just as we already know it
        <- '\Sigma for making sigmas-of-sigmas
        <- 'indx for exhibiting the functoriality
            -> For recursive arguments
        <- '1 for end of description
\end{structure}

\subsection{Examples}

\begin{structure}
<- Nat
    <- Sum of zero, suc
    <- zero case: done
    <- suc case: leave open and done
    -> NatD Z = 1 + Z
\end{structure}

\begin{structure}
<- List
    <- Sum of nil, cons
    <- nil case: done
    <- cons case: product of X with leave open and done
    -> ListD X Z = 1 + X * Z
\end{structure}

\begin{structure}
<- Tree
    <- sum of leaf, node
    <- leaf case: done
    <- node case: product of X with two leave open and done
    -> TreeD X Z = 1 + X * Z * Z
\end{structure}

\begin{structure}
<- Fictive object [figure 'data Desc']
    -> Must be read as a type signature
    -> See further for its actual implementation
        <- Subject to our levitation exercise
\end{structure}

\subsection{Fix-point}

\begin{structure}
<- Build the fix-point of functors
    <- See examples: need to build their initial algebra
    -> Extend the type theory with Mu/Con [figure]
        <- Straightforward definition of a fixpoint
            <- Interpret D with (Mu D) as subobjects
\end{structure}

\begin{structure}
<- Extending type propagation
    <- Data-type declaration turns into definitions
        -> Straightforward translation to Desc
        -> Creation of a variable referring to the structure
    <- Push Mu to an applied name [figure]
        -> Direct integration into the type propagation machinery
    <- Labelled Mu
        /> Just mention the possibility of labelling, no details required
        -> For the user, objects have names rather than Mu of codes
    -> Coded presentation is practical
        <- The user never see a code
\end{structure}

\begin{structure}
<- Elimination on Mu
    <- We are used to foldD : \forall X. (desc D X -> X) -> mu D -> X
        /> Not dependent
        -> Cannot express some (which one again?) properties
    -> Develop a dependent induction
        <- Everywhere/All
        <- Induction
    -> *Generic*
\end{structure}

\section{Levitating the universe of descriptions}

\subsection{Implementing finite sets}

\begin{structure}
<- Recall typing rules of 1st section
    -> Make clear they were just promises
    -> Can be implemented now
        <- Simply List UId
\end{structure}

\begin{structure}
<- Consequences
    -> Type theory doesn't need to be extended with EnumU, NilE, and ConsE
        <- EnumU == Mu EnumUD
        <- NilE, ConsE are just tags
    -> Do not need a specific \spi eliminator
        <- \spi is an instance of the generic eliminator
            <- Code?
    -> Anything else remains the same (switch, EnumT, 0, 1+)
\end{structure}

\begin{structure}
<- Summary of the operation
    <- The content of the type theory is exactly the same
        <- before == after
    /> type naming scheme condenses
        <- Replace named constructors by codes in the universe of data-types
    -> Our next step is a similar move (in essence)
        /> Condenses the entire naming scheme of data-types
\end{structure}

\subsection{Implementing descriptions}

\begin{structure}
<- Realizing our promises
    <- We are going to implement Desc
    /> Desc is itself a data-type
        <- Same situation as EnumU
            <- We want to benefit from generic operations
        -> It ought to be encoded in itself
\end{structure}

\subsubsection{First try}

\begin{structure}
<- A partial implementation
    <- '1 and 'indx are easy
    <- 'sigma is partially doable
        /> lack the ability to do an higher-order inductive call
    -> Show partial code [figure]
\end{structure}

\subsubsection{Second try}

\begin{structure}
<- Extending the universe of description
    -> With higher-order induction
    <- Intuition: index elements in X by H, and go on reading
        -> indx is isomorph to hindx for H = 1
    /> Keep indx
        <- First order!
        -> Extensionally equal to hindx 1
        /> Practically, definitional equality on Sigma/Pi cannot cope with it
    -> Show DescD code
\end{structure}

\subsubsection{Final move}

\begin{structure}
<- Subtlety: translation of [ ... ]
    -> Let us do it manually
        -> Code with problem for the motive of switch
\end{structure}

\begin{structure}
<- The magician trick
    <- Our problem is to give a motive for switch
        /> We perfectly know what it ought to be: \_ -> DescD
    -> Solution: extend the type theory with a special purpose switchD
        -> Only extension required to the type theory!
        -> Hidden away to the user by the syntactic sugar
            -> Sufficient to ensure unavailability as a raw operator
            <- Another instance of type propagation
\end{structure}

\begin{structure}
<- Generic programming now!
    <- Desc is just data
        -> Can be manipulated
    <- Free induction scheme on Desc
        -> Ability to inspect data-types
        -> Ability to program on data-types
\end{structure}

\subsubsection{Desc, atomically}

\begin{structure}
<- Adding hindx have introduced some duplication
    <- indx == hindx 1
    -> We can factor out commonalities 
        /> Obtain an equivalent presentation
        /> Still embeddable (refer to the Agda model)
\end{structure}

\begin{structure}
<- Give new presentation [figure]
    <- hindx have introduced the notion of function space: 'Pi
    <- hindx and indx are both composed by a binary product and a left open term: 'x and 'id 
    -> Straightforward translation to the new system [equation]
\end{structure}

\subsection{The generic catamorphism}

\begin{structure}
<- Making cata
    ???
\end{structure}

\subsection{The generic Free Monad}

\begin{structure}
!!! EARLIER !!!
<- Tagged description
    <- Form TDesc = List (UId x Desc) [equation]
    <- Follow usual sums-of-product presentation of data-type
        <- Finite set of constructors
        <- Then whatever you want
    -> Any Desc data-type can be turned into this form
        -> No loss of expressive power
        /> Garantee a ``constructor form''
\end{structure}

\begin{structure}
<- A generic program: the free monad construction
    <- Recall free monad construction in Haskell
        -> Based on a functor F
    <- Note that the free monad construction is itself defined by a functor
        -> Extract it
    <- Encode it in the Desc world [equation]
        <- F is the Desc we start with
        <- The free monad functor is what we have just defined
        <- [\_]* : Desc -> Set -> Desc
           [\_]* D X = 'cons ['var ('sigma X (\_ -> '1))] D
        -> Mu does the fix-point
\end{structure}

\begin{structure}
<- A generic program: monadic substitution [equation]
    <- subst : \forall T X Y. mu ([T]* X) -> (X -> mu ([T]* Y)) -> mu ([T]* Y)
    -> Using Fold
    
\end{structure}

\section{Indexing descriptions}

\begin{structure}
!!! Need Help !!!
<- Motivation
    <- Desc: expressivity of simply-typed data-types: inductive types
        <- Values do not influence types
    /> Example: Vectors
        <- Cannot be defined by just induction
            <- Vectors of all size need to be defined at the *same* time
            -> Defined as a *family* of types
                -> Index
        -> I -> IDesc I: Inductive family
    ???
\end{structure}

\subsection{From Desc to IDesc}

\begin{structure}
<- Labelling Id
    <- We had: data Desc : Set -> Set
    -> We want: data IDesc : (I -> Set) -> Set
        <- Indexed functor (?)
        -> It is sufficient to label Id
            <- Where the functor is built
\end{structure}

\begin{structure}
<- Also replacing '1 by 'const  [figure]
    <- For convenience
        <- 'const X equivalent to 'sigma X (\_ -> '1)
        /> Easier to abstract
            <- Extensionally same
            /> 'const more useful in practice
\end{structure}

\subsection{Examples}

\begin{structure}
<- Nat
    -> [equation]
    <- Non-indexed types lives in IDesc 1
        -> This applies to all previous examples
\end{structure}

\begin{structure}
<- Levitation [figure]
    <- Following Desc encoding
        /> Note: simple data-type
            -> Live in IDesc 1
    -> Behind the scene, relies on the special purpose switchD
\end{structure}

\begin{structure}
<- Untyped lambda terms [figure]
    ???
\end{structure}

\subsection{Constrained constructors}

\begin{structure}
<- Assuming a suitable notion of definitional equality for I
    ???
\end{structure}

\begin{structure}
<- Fin [figure]
    <- Presentation with equality constraints
    ???
\end{structure}

\begin{structure}
<- Vectors
    ???
\end{structure}

\begin{structure}
<- GADTS
    ???
\end{structure}

\begin{structure}
<- Brady optimization
    <- Source to source translation
    <- Able to remove some constraints
    -> Example: Fin [figure]
\end{structure}

\subsection{Free IMonad}

\begin{structure}
<- Untyped lambda terms
    ???
\end{structure}

\begin{structure}
<- IDesc
    ???
\end{structure}

\section{Discussion}

\begin{structure}
!!! Need Help !!!
<- Universe stratification
    <- Stratified agda model
        <- Fully stratified
        <- Proof of iso between host and embedding
    ???
\end{structure}

\end{document}
