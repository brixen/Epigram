\section{Levitating the Universe of Descriptions}
\label{sec:desc-levitate}

In this section, we will fulfil our promises and show how we implement
the signatures, first for the enumerations, and then for the codes of
the $\Desc$ universe.  Persuading this to perform was a perilous
pedagogical peregrination for the protagonist.  Our method was indeed to
hardwire constants implementing the signatures specified above, in the
first instance, but then attempt to replace them, step by step, with
\emph{definitions}: ``Is \(2+2\) still \(4\)?'', ``No, it's a loop!''.
But we did find a way, so now we hope to convey to the reader the
dizzy feeling of levitation, without the falling.



\subsection{Implementing finite enumerations}

\begin{wstructure}
<- Recall typing rules of 1st section
    -> Make clear they were just promises
    -> Can be implemented now
        <- Simply List UId
\end{wstructure}

In Section~\ref{sec:finite-sets}, we specified the
finite sets of tags. We are going to implement the $\EnumU$ type former and
its constructors. Recall:
%
\[\Type{\EnumU}\qquad\Bhab{\NilE}{\EnumU}\qquad
\Bhab{\ConsE{(\Bhab{\M{t}}{\UId})}{(\Bhab{\M{E}}{\EnumU})}}{\EnumU}
\]
%
The $\NilE$ and $\SYMBConsE$ constructors are just the `nil' and
`cons' or ordinary lists, with elements from \(\UId\).
Therefore, we
implement:
%
\[
\EnumU \mapsto \Mu{(\ListD\: \UId)}
\qquad
\NilE \mapsto \ListNil
\qquad
\ConsE{\M{t}}{\M{E}} \mapsto \ListCons{\M{t}}{\M{E}}
\]


\begin{wstructure}
<- Consequences
    -> Type theory doesn't need to be extended with EnumU, NilE, and ConsE
        <- EnumU == Mu EnumUD
        <- NilE, ConsE are just tags
    -> Do not need a specific \spi eliminator
        <- \spi is an instance of the generic eliminator
            <- Code?
    -> Anything else remains the same (switch, EnumT, 0, 1+)
\end{wstructure}

Let us consider the consequences. We discover that the type
theory does not need to be extended with a special type former $\EnumU$,
or special constructors $\NilE$ and $\SYMBConsE$. 
Moreover, the $\spi{\M{E}}{\M{P}}$ operator, computing tuple types
of \(\M{P}\)s by recursion on \(\M{E}\) need not be hardwired: we can
just use the generic $\F{ind}$ operator, as we would for any ordinary
program.

Note, however, that the universe decoder \(\EnumT{\M{E}}\) \emph{is}
hardwired, as are the primitive \(\Ze\) and \(\Su\) that
we use for low-level values, and indeed the \(\SYMBswitch\) operator.
We cannot dispose of data altogether! We have, however, gained
the ordinariness of the enumeration \emph{codes}, and hence of generic
programs which manipulate them. Our next step is similar: we are going to
condense the entire naming scheme of datatypes \emph{into itself}.

%% Apart from these changes, we are left with implementing the other
%% components of finite sets. This consists of $\EnumT$, $\Ze$, $\Su$, as
%% well as the $\F{switch}$ operator. Note that the actual implementation
%% of $\EnumU$ does not influence our implementation of $\EnumT$: be they
%% hard-coded or codes in the $\Desc$ universe, the $\EnumU$ objects
%% behave the same. We have witnessed this effect when carrying the
%% operation in Epigram, moving from an hard-coded presentation to a
%% self-hosted one. Absolutely no change to the $\EnumT$ objects was
%% required.

\begin{wstructure}
<- Summary of the operation
    <- The content of the type theory is exactly the same
        <- before == after
    /> type naming scheme condenses
        <- Replace named constructors by codes in the universe of datatypes
    -> Our next step is a similar move (in essence)
        /> Condenses the entire naming scheme of datatypes
\end{wstructure}

%In this section, we have replaced a low-level presentation of finite
%sets by a self-hosted one, expressed in the universe of
%descriptions. However, formally, the content of the type theory
%remains unchanged: objects that were present before the modification
%are still there. Conversely, we have not introduced any spurious
%object.

%If not on the content, this modification had an effect on the
%names. The type naming scheme of the type theory has condensed: named
%type formers ($\EnumU$) and constructors ($\NilE$ and $\ConsE$) are
%now replaced by codes and their fixpoint in the universe of
%descriptions. In essence,

\subsection{Implementing descriptions}

\begin{wstructure}
<- Realising our promises
    <- We are going to implement Desc
    /> Desc is itself a datatype
        <- Same situation as EnumU
            <- We want to benefit from generic operations
        -> It ought to be encoded in itself
\end{wstructure}

We shall now fulfil our implementation promises, encoding the universe
of descriptions. In and of itself, the codes, $\Desc$, is nothing but
a datatype. We are in the same situation as with $\EnumU$: we ought to
be able to describe the codes of $\Desc$ in $\Desc$ itself. Hence,
this code would be a first-class citizen, born with the standard,
generic equipment of datatypes.

\subsubsection{First attempt}

\begin{wstructure}
<- A partial implementation
    <- '1 and 'indx are easy
    <- 'sigma is partially doable
        /> lack the ability to do an higher-order inductive call
    -> Show partial code [figure]
\end{wstructure}

Our first attempt gets stuck quite quickly:
%
\[\stk{
\DescD : \Desc \\
\DescD \mapsto
  \tada{\stkm{\DUnit\\ \SYMBDSigma\\ \SYMBDIndx}}
       {\stkm{ \DUnit                                \\
         \DSigma{\Set}{\LAM{\V{S}} \SHED}      \\
         \DIndx{\DUnit}    }                    } \\
%\begin{array}{@{}ll}
%\DescD \mapsto \DSigma{\!}{\!} & (\EnumT{[ \DUnit, \DSigma{\!}{\!}, \DIndx{\!} ]})  \\
%                               & \left[\begin{array}{l}
%                                   \DUnit                                \\
%                                   \DSigma{\Set}{\LAM{\V{S}} \SHED}      \\
%                                   \DIndx{\DUnit}                        \\
%                                 \end{array}
%                                 \right]
%\end{array}
}\]
%
Let us explain where we stand. Much as
we have done so far, we first offer a constructor choice from
$\DUnit$, $\SYMBDSigma$, and $\SYMBDIndx$. The reader will notice
that the `tagged' notation we have used for the $\Desc$ constructors now
fully makes sense: these were actually the tags we are defining.
For $\DUnit$, we immediately reach the end of the description. For
$\SYMBDIndx$, there is a single recursive argument. Describing
$\SYMBDSigma$ is problematic. Recall the specification of
$\SYMBDSigma$:
%
\[
\DSigma{(\Bhab{\V{S}}{\Set})}{(\Bhab{\V{D}}{\V{S} \To \Desc})} : \Desc\\
\]
%
So, we first pack a  $\Set$, $\V{S}$. We should then like
a recursive argument \emph{indexed} by $\V{S}$, but
that is an \emph{exponential}, and our presentation is entirely
first-order so far, delivering only sums-of-products. To code our
universe, we must first enlarge it!


\subsubsection{Second attempt}

\begin{wstructure}
<- Extending the universe of description
    -> With higher-order induction
    <- Intuition: index elements in X by H, and go on reading
        -> indx is isomorph to hindx for H = 1
    /> Keep indx
        <- First order!
        -> Extensionally equal to hindx 1
        /> Practically, definitional equality on Sigma/Pi cannot cope with it
    -> Show DescD code
\end{wstructure}

In order to capture a notion of higher-order induction, we add a code
$\SYMBDHindx$ that takes an indexing set $\V{H}$. This amounts to give
a recursive subobject for each element of $H$.
%
\[\stk{
    \DHindx{(\Bhab{\M{H}}{\Set})}{(\Bhab{\M{D}}{\Desc})} : \Desc
    \smallskip \\
    \descop{\DHindx{\V{H}}{\V{D}}}{\V{X}}     
        \mapsto 
            \TIMES{(\V{H} \To \V{X})}{\descop{\V{D}}{\V{X}}} \\
}\]


Note that up to isomorphism, $\SYMBDIndx$ is subsumed by
$\DHindx{\Unit}{\!}$. However, the apparent duplication has some
value.  Unlike its counterpart, $\SYMBDIndx$ is first-order: we prefer
not to demand dummy functions from \(\Unit\) in ordinary data,
e.g. \(\NatSuc{(\LAM{\_}n)}\). It is na{\"\i}ve to imagine that up to
isomorphism, any representation of data will do.  First-order
representations are finitary by construction, and thus admit a richer,
componentwise decidable equality that functions may in
general possess.\footnote{E.g., extensionally, there is one inhabitant of
\(\EnumT{\void}\To\Nat\); intensionally, there is a countable infinitude
which it is not safe to collapse.}

We are now able to describe our universe of datatypes:
%
\[\stk{
\DescD : \Desc \\
\DescD \mapsto\tada
{\stkm{ \DUnit\\ \SYMBDSigma\\ \SYMBDIndx\\ \SYMBDHindx}}
{\stkm{
\DUnit                                            \\
                                   \DSigma{\Set}{\LAM{\V{S}} \DHindx{\V{S}}{\DUnit}}   \\
                                   \DIndx{\DUnit}                                    \\
                                   \DSigma{\Set}{\LAM{\_} \DIndx{\DUnit}}
}}
}\]
%
The $\DUnit$ and $\SYMBDIndx$ cases remain unchanged, as expected. We
successfully describe the $\SYMBDSigma$ case, by a simple appeal to
the higher-order induction on $\V{S}$. The $\SYMBDHindx$ case
consists in packing a $\Set$ with a recursive argument.

At a first glance, we have achieved our goal. We have described the
codes of the universe of descriptions. Taking the fixpoint of \(\descop{\DescD}\)
gives us a datatype exactly like $\Desc$. Might we be
so bold as to take \(\Desc \mapsto \Mu{\DescD}\) as the levitating
definition? If we do, we shall come down with a bump! 
To complete our levitation, just as in the magic trick, requires
hidden assistance. Let us explain the problem and reveal the `invisible
cable' which fixes it.


\subsubsection{Final move}

\begin{wstructure}
<- Subtlety: translation of [ ... ]
    -> Let us do it manually
        -> Code with problem for the motive of switch
\end{wstructure}

The definition \(\Desc \mapsto \Mu{\DescD}\) is circular,
but the offensive recursion is concealed by a prestidigitation.
Expanding \(\toDesc{-}\) and propagating types as in
Figure~\ref{fig:type-checking} reveals the
awful truth:
\[
\Desc\mapsto
\Mu{\stk{(\DSigma{\EnumT{\sqr{ \DUnit\:\: \SYMBDSigma\:\: \SYMBDIndx\:\: \SYMBDHindx}}\\}
    {\;\SYMBswitch\:\sqr{ \DUnit\:\: \SYMBDSigma\:\: \SYMBDIndx\:\: \SYMBDHindx}\:(\LAM{\_}\Desc)\\
\;\sqr{\stkm{
\DUnit                                            \\
                                   \DSigma{\Set}{\LAM{\V{S}} \DHindx{\V{S}}{\DUnit}}   \\
                                   \DIndx{\DUnit}                                    \\
                                   \DSigma{\Set}{\LAM{\_} \DIndx{\DUnit}}
}}})}}
\]
The recursion shows up only because we must specify the return type
of the general-purpose \(\F{switch}\), and it is computing a \(\Desc\)!
Although type propagation
allows us to hide this detail \emph{when defining a function}, we cannot
readily suppress this information and check types
when \(\F{switch}\) is fully applied.

\begin{wstructure}
<- The magician trick
    <- Our problem is to give a motive for switch
        /> We perfectly know what it ought to be: \_ -> DescD
    -> Solution: extend the type theory with a special purpose switchD
        -> Only extension required to the type theory!
        -> Hidden away to the user by the syntactic sugar
            -> Sufficient to ensure unavailability as a raw operator
            <- Another instance of type propagation
\end{wstructure}

%What happens if we unfold the definition? We ought to build the following term:
%
%\[
%\PLAM{\V{x}}{(\EnumT{\V{E}})} \switch{\V{E}}{(\LAM{\_} %\Mu{\DescD})}{\V{\pi^f}}{\V{x}}
%\]
%
%But this is quite problematic. We are still in the process of
%constructing $\DescD$, and the motive of $\F{switch}$ is abruptly
%begging for this very same $\DescD$. Despite our willingness, we
%cannot materialise such motive. However, we perfectly know what the
%motive is.

We are too close to give up now. If only we did not need to
supply that return type, especially when we know what it must be.
We eliminate the recursion by \emph{specialising} \(\F{switch}\):
%
\[
\F{switchD} : \PITEL{\V{E}}{\EnumU}   \To
                (\spi{\V{E}}{\LAM{\_} \Desc}) \To
                \EnumT{\V{E}} \To \Desc
\]
%
The magician's art rests here, in this extension. We conceal it
behind a type propagation rule for \(\F{switchD}\) which we apply
with higher priority than for \(\F{switch}\) in general.
%
\[
\Rule{\Gamma \Vdash
  \propag{\push{\sqr{\vec{t}}}{\spi{\M{E}}{\PLAM{x}{\EnumT{E}}\Desc}}}
                           {\M{t'}}}
     {\Gamma \Vdash
\propag{\push{\sqr{\vec{t}}}{\EnumT{\M{E}}\To\Desc}}
 {\switchD{\M{E}}{\M{t'}}}}
\]
As a consequence, our definition above now propagates without
introducing recursion. Of course, by pasting together the declaration
of \(\Desc\) and its internal copy, we have made it appear in its own
type. Hardwired as a \emph{fait accompli}, this creates no regress,
although one must assume the definition to recheck it\footnote{Our
  Agda model does not formalize the $\SYMBswitchD$
  construction. However, it proves the isomorphism between the defined
  descriptions and the coded ones. The role of $\SYMBswitchD$ is to
  collapse this isomorphism, hence identifiying defined and coded
  descriptions.}. Alternatively, we could have extended $\Desc$ with a
code for \emph{finite} sums, internalizing the $\SYMBswitch$ in the
interpretation function:
%%
\[\stk{
    \Dsigma{(\Bhab{\V{E}}{\EnumU})}
           {(\Bhab{\V{B}}{\spi{\V{E}}{\LAM{\_}{\Desc}}})} : \Desc
    \smallskip \\
    \descop{\Dsigma{\V{E}}{\V{B}}}{\V{X}}     
        \mapsto 
            \SIGMAS{\Bhab{\V{x}}{\EnumT{\V{E}}}}
                   {\descop{\switch{\V{E}}{(\LAM{\_}{\Desc})}{\V{B}}{\V{x}}}{\V{X}}}    
}\]
%%
Using $\SYMBDsigma$ to switch over the $\Desc$ constructors, we avoid
mention of $\Desc$ while levitating it. The $\SYMBswitch$ operator is
pushed into the interpretation function, at which point $\Desc$ indeed
exists.

%% * There exists alternative
%% **   <- All we want is to avoid mention of Desc
%% **   -> Add a code for finite sigma : $\sigma : (e : \EnumU) -> \pi e \Desc -> \Desc$
%% **       <- Take a finite set in argument
%% **       <- Interpreted as a switch
%% **       -> No more need to mention Desc during its construction
%% **           <- Pushed into intrepretation, at which time it exists

\begin{wstructure}
<- Generic programming now!
    <- Desc is just data
        -> Can be manipulated
    <- Free induction scheme on Desc
        -> Ability to inspect datatypes
        -> Ability to program on datatypes
\end{wstructure}


We have levitated \(\Desc\). Beyond its pedagogical value, this
exercise has several practical outcomes. First of all, it reveals that
the $\Desc$ universe is just plain data. As any piece of data, it can
therefore be inspected and manipulated. Moreover, it is expressed in
the $\Desc$ universe. As a consequence, it is equipped, for free, with
an induction principle. So, our ability to inspect and program with
$\Desc$ is not restricted to a meta-language: we now have all the
necessary equipment in the theory to \emph{program} over
datatypes. \emph{Generic programming is just
  programming}.


\subsection{The generic catamorphism}

\begin{wstructure}
<- Making cata
    <- Present the type signature
    <- Starts with a call to generic induction
        <- induction on Desc!
        /> Show types at hand
        -> Explain how to use inductive hypothesis
    <- Implement the 'replace' function
    -> Dependent-typeless catamorphism 
\end{wstructure}

In Section~\ref{sec:desc-fix-point}, we hardwired a dependent
$\F{ind}$unction principle, instead of the catamorphism. However, in
some circumstances, the full power of a dependent elimination is not
necessary. Let us now derive the catamorphism
from $\F{ind}$ principle.

\newcommand{\cata}{\F{cata}}

The catamorphism is defined by induction on the description $\V{D}$,
with a readily propagated non-dependent return type $\V{T}$.
Given a node $\V{xs}$
and the induction hypotheses, the method ought to build an element of
$\V{T}$. Provided that we know how to make an element of
$\descop{\V{D}}{\V{T}}$, this step will be performed by the algebra
$\V{f}$. Let us take a look at this jigsaw:
%
\[\stk{
\cata : \PITEL{\V{D}}{\Desc}
           \PI{\V{T}}{\Set}
           (\descop{\V{D}}{\V{T}} \To \V{T}) \To 
           \Mu{\V{D}} \To \V{T} \\
\cata\: \V{D}\: \V{T}\: \V{f} \mapsto
  \sind \LAM{\V{xs}}\LAM{\V{hs}} \V{f}\: \SHED
}\]
% 
We are left with filling the hole. Recall that we have
\(\Bhab{\V{xs}}{\descop{\V{D}}{\Mu{\V{D}}}}\) and
\(\Bhab{\V{hs}}{\All{\V{D}}{\Mu{\V{D}}}{(\LAM{\_} \V{T})}{\V{xs}}}\)
at hand. Our goal is to make an element of
\(\descop{\V{D}}{\V{T}}\). $\V{xs}$ is of the right shape, but its
sub-elements are of the wrong type. On the other hand, for each
sub-element of $\V{xs}$, $\V{hs}$ gives us the corresponding element
in $\V{T}$.  Therefore, to construct an element of
\(\descop{\V{D}}{\V{T}}\), we must replace the recursive components of
\(\V{xs}\) by their counterparts from \(\V{hs}\). Let us write a
program to do that---please forgive us if we lapse to a pattern
matching notation, for readability's sake.
%
\[\stk{
\F{replace} : \stk{\PITEL{\V{D}}{\Desc}
                   \PITEL{\V{X},\V{Y}}{\Set}\\
                   \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
                   \All{\V{D}}{\V{X}}{(\LAM{\_}\V{Y})}{\V{xs}} \To
                   \descop{\V{D}}{\V{Y}}} \\
\begin{array}{@{}l@{\:\:\mapsto\:\:}l}
\F{replace}\: \DUnit\:          \V{X}\: \V{Y}\: \Void\:          \Void   &
    \Void  \\
\F{replace}\: (\DSigma{\V{S}}{\V{D}})\: \V{X}\: \V{Y}\: \pair{\V{s}}{\V{d}}{}\: \V{d'}  &
    \pair{\V{s}}{\F{replace}\: (\V{D}\: \V{s})\: \V{X}\: \V{Y}\: \V{d}\: \V{d'}}{} \\
\F{replace}\: (\DIndx{\V{D}})\:     \V{X}\: \V{Y}\: \pair{\V{x}}{\V{d}}{}\: \pair{\V{y}}{\V{d'}}{} &
    \pair{\V{y}}{\F{replace}\: \V{D}\: \V{X}\: \V{Y}\: \V{d}\: \V{d'}}{} \\
\F{replace}\: (\DHindx{\V{H}}{\V{D}})\: \V{X}\: \V{Y}\: \pair{\V{f}}{\V{d}}{}\: \pair{\V{g}}{\V{d'}}{} &
 \pair{\V{g}}{\F{replace}\: \V{D}\: \V{X}\: \V{Y}\: \V{d}\: \V{d'}}{}
\end{array}
}\]
%
Filling the hole in $\F{cata}$ with \(\F{replace}\: \V{D}\:
\Mu{\V{D}}\: \V{T}\: \V{xs}\: \V{hs}\) closes the problem. In the
type theory, we have built a generic catamorphism. Any datatype will
now come equipped with this operation, for free.

%% The astute reader will have been struck by the type of $\F{replace}$:
%% it is \emph{almost} the morphism part -- sometimes called \emph{map}
%% -- of the functor $\V{D}$ from $\V{X}$ to $\V{Y}$ in $\Set$. Just as
%% the $\F{induction}$ is the dependent version of $\cata$, $\F{replace}$
%% is the dependent version of the map, which uses the induction
%% hypotheses. For space reason, we will not present the non-dependent
%% map. It can be found in the Agda model.

\begin{wstructure}
<- Deriving generic functions
    <- Taking a Desc and computing a function
        <- Desc comes equipped with an induction principle
        -> Ability to compute more functions from it
            -> More generic functions
    <- Inspecting datatypes
        <- All described byu a Desc code
        -> Ability to explore the code
            <- Desc equipped with an induction principle
            -> Build new objects based on that structure
\end{wstructure}

With this example, we have shown how we can derive a generic
operation, the catamorphism, from a pre-existing generic operation,
the induction principle. This has been made possible by our ability to
manipulate descriptions as first-class objects: the catamorphism is,
basically, a function mapping a $\Desc$ to a datatype specific
operation. This is a form of polytypic programming, as we learned from
PolyP~\cite{jansson:polyp}.

%% Moreover, the $\F{replace}$ function demonstrates the benefit of an
%% approach based on universes. The datatypes living in the universe of
%% descriptions, we are able to \emph{inspect} them. As shown by
%% $\F{replace}$, it is easy to explore these structures, as well as
%% building new ones.

\subsection{The generic free monad}
\label{sec:desc-free-monad}

\begin{wstructure}
<- A generic program: the free monad construction
    <- Recall free monad construction in Haskell
        -> Based on a functor F
    <- Note that the free monad construction is itself defined by a functor
        -> Extract it
\end{wstructure}

In this section, we will turn to a more ambitious generic operation on
datatypes. Given a functor, represented as a tagged description, we
build the free monad over this functor.

\newcommand{\FMFreeMonad}{\D{FreeMonad}}
\newcommand{\FMFreeMonadD}{\D{FreeMonadD}}
\newcommand{\FMVar}{\C{Var}}
\newcommand{\FMComposite}{\C{Composite}}

Let us recall the free monad construction in, say, Haskell. Given a
functor \texttt{f}, the free monad over \texttt{f} is defined by the
following datatype:
%
\begin{code}
data FreeMonad f x
    = Var x
    | Composite (f (FreeMonad f x))
\end{code}
%
Being an inductive type, this $\FMFreeMonad$ datatype is itself
defined by a pattern functor. It is given by:
%
\[
\FMFreeMonadD\: \V{F}\: \V{X}\: \V{Z} \mapsto \V{X} \mathop{\D{+}} \V{F} \V{Z}
\]

\begin{wstructure}
    <- Encode it in the Desc world [equation]
        <- F is the Desc we start with
        <- The free monad functor is what we have just defined
        <- [\_]* : Desc -> Set -> Desc
           [\_]* D X = 'cons ['var ('sigma X (\_ -> '1))] D
        -> Mu does the fixpoint
\end{wstructure}

In our setting, the free monad construction will take the functor as a
tagged description, a set $\V{X}$ of variables, and will compute the
tagged description of the corresponding free monad. Implementing this
function is surprisingly easy:
%
\[\stk{
\FreeMonad{\_} : \TagDesc \To \Set \To \TagDesc \\
\FreeMonad{\pair{\V{E}}{\V{D}}{}}\:\V{X} \mapsto
    \pair{\pair{\DVar{}}{\V{E}}{}}
         {\pair{\DSigma{\V{X}}{\DUnit}}{\V{D}}{}}{}
}\]
%
We simply add a constructor, $\SYMBDVar$, and define its argument to
be a $\DSigma{\V{X}}{\DUnit}$, that is an element of $\V{X}$. We keep
$\V{E}$ and $\V{D}$ as they were, hence leaving the other constructors
unchanged. Unfolding the interpretation of this definition, we
convince ourselves that this corresponds to the functor
$\FMFreeMonadD$. The fixpoint operation ties the knot and gives us
the full-blown free monad construction.

\begin{wstructure}
<- A generic program: monadic substitution [equation]
    <- subst : \forall T X Y. mu ([T]* X) -> (X -> mu ([T]* Y)) -> mu ([T]* Y)
        -> Using Fold
\end{wstructure}

Of course, we must equip the resulting datatypes with operations
delivering a monadic interface. As expected, \(\LAM{\x}\DVar{\x}\)
plays the r\^ole of \return, embedding variables into terms. The
\bind operation corresponds to \emph{substitution}. We will now
implement it, as a generic function.


\newcommand{\subst}{\F{subst}}
\newcommand{\apply}{\F{apply}}

Our implementation will appeal to the $\cata$ function developed
previously. So, let us write down the types, and fill as many
arguments to $\cata$ as possible:
%
\[\stk{
\begin{array}{@{}ll}
\subst : & \PITEL{\V{D}}{\TagDesc}
           \PI{\V{X}, \V{Y}}{\Set} 
           (\V{X} \To \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}) \To \\
         & \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{X}}})} \To
           \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})} 
\end{array} \\
\subst\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma} \mapsto
  \cata\: (\toDesc{\FreeMonad{\V{D}}{\V{X}}})\: 
          \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}\: 
          \SHED
}\]
%
We are left with implementing the algebra of the catamorphism. Its
role is to catch appearances of $\DVar{\V{x}}$ and replace them by
$\V{\sigma}\: \V{x}$. This corresponds to the following definition:
%
\[\stk{
\begin{array}{@{}ll}
\apply : & \PITEL{\V{D}}{\TagDesc} 
           \PI{\V{X}, \V{Y}}{\Set} 
           (\V{X} \To \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}) \To \\
         & \descop{\toDesc{\FreeMonad{\V{D}}{\V{X}}}}{\Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}} \To
           \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}
\\
\end{array} \\
\begin{array}{@{}l@{\:\mapsto\:\:}l}
\apply\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma}\: \pair{\SYMBDVar}{\V{x}}{}   & \V{\sigma}\: \V{x}                   \\
\apply\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma}\: \pair{\V{c}}{\V{xs}}{} & \Con{\pair{\V{c}}{\V{xs}}{}}
\end{array}
}\]

\begin{wstructure}
    -> Consequences
        <- We have free monad datatype
            <- Term + variables
        <- We have monad operations
            <- Return / var
            <- Substitution / bind
\end{wstructure}

Filling the sub-goal with $\apply\: \V{D}\: \V{X}\: \V{Y}\:
\V{\sigma}$ completes the implementation. To sum up, we have
implemented the free monad construction for an arbitrary tagged
description. This gives the developer the ability, for any datatype,
to extend it with a notion of variable. Then, we have equipped this
structure with the corresponding monadic operations, \bind and
\return. This construction is an example of type-indexed
datatype~\cite{hinze:generic-haskell}, as found in Generic Haskell:
from a datatype, we build a new datatype and equip it with its
structure.

\begin{wstructure}
<- Deriving new data-structure and functions on them
    <- Computing the Free Monad of a datatype
        <- Derive new data-structure from previous one
            <- It is just code
        /> New data-structure comes with some equipment
    <- Computing new functions on computed datatypes
        <- If data comes with structure, we ought to be able to capture it
            <- Induction on Desc
            -> Ability to compute over data
\end{wstructure}

%% Candidate for removal:
%% With the free monad construction, we have seen two kinds of generic
%% operations. Firstly, we have derived a new data-structure from another
%% one: we make the free monad from its underlying functor. To do so, we
%% crucially rely on the fact that datatypes are nothing but codes. We
%% are therefore entitled to modify this code and, in this case, extend
%% it. Extending a datatype might give rise to a more structured object,
%% as was the case here.  So, secondly, we have equipped this new
%% datatype with its inherent structure: the \bind\ and
%% \return\ operations. We have been able to build them as generic
%% functions.

\subsection{Skyhooks all the way up?}

%% * Desc in Desc
%% ** /> Blur the lines between implementation and reflection
%% ** /> Abusing the paradoxical nature of Set : Set

In this section, we have seen how to \emph{levitate}
descriptions. From this unusual situation, several questions naturally
arise. First, we have blurred the line between the implementation of
data-types and their reflection in themselves. Second, we have abused
the paradoxical nature of $\Bhab{\Set}{\Set}$ to flatten the hierarchy
of descriptions. We shall now be more precise about these points.

%% * Summary 
%% ** <- What is the equipment for making data-types
%% ** <- What is reflected, what is implemented
%% ** <- (table 1)

Let us first clarify the status of the implementation. The kit for
making datatypes is summed up in Table~\ref{tab:sumup-operators}. For
each operation, we describe its role and its status, making clear
which components are self-described and which ones are actually
implemented.

%% * Paradox
%% ** <- How do we bottom out in a stratified setting?
%% ** <- Spiral
%% ***    <- Encoding of DescD_n : Desc_{n+1}
%% ***    <- Desc_n = Mu DescD_n : Set_{n+1}
%% ** <- Agda model: Desc_42
%% ***    <- No dependent pattern-matching
%% ***    <- No IR
%% ***    <- Normal universes
%% ***    -> Straight Agda (UTT)
%% ** <- ``Self-encoding'' only in a level polymorphic sense
%% ***    -> Agda model: set poly

To tackle the apparent circularity of our construction, let us
consider how it bottoms out in a stratified setting. Using the
informal level annotations of Section~\ref{sec:universe-desc}, we have
that \(\Bhab{\DescD_n}{\Desc_{n+1}}\), hence \(\Bhab{\Desc_n \mapsto
  \Mu{\DescD_n}}{\Set_{n+1}}\). Therefore, there is no circularity in
the description of descriptions: assuming an hardwired $\Desc_N$
universe, we can build the tower of descriptions down to
$\Desc_0$\footnote{We have modelled this process in Agda, hardwiring
  $\Desc_{42}$ in $\Set_{43}$, then going down. This model does not
  rely on dependent pattern-matching, induction-recursion, nor set
  polymorphism.}. Hence, in a stratified system, the `self-encoded'
nature of $\Desc$ appears only in a set polymorphic sense: the
principal type of the levitating description generalizes to the type
of $\Desc$ itself\footnote{This is witnessed in our set polymorphic
  model in Agda. Set polymorphism is an experimental feature of
  Agda. Although not backed by theoretical works, it is a conservative
  extension of Agda that is generally accepted as free of paradox.}.

\begin{table}

{\small

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Object                & Role                        & Status \\
\hline
\hline
$\EnumU$              & Build finite sets           & Levitated \\
\hline
$\Desc$               & Describe pattern functors   & Levitated \\
\hline
$\SYMBdescop{\_}$     & Interpret descriptions      & Hardwired \\
\hline
$\SYMBMu$, $\SYMBCon$ & Define, inhabit fixpoints   & Hardwired \\
\hline
$\SYMBind$, $\SYMBAll$, $\SYMBall$  
                      & Induction principle         & Hardwired \\
\hline
\end{tabular}
\end{center}
}

\caption{Summary of constructions on Descriptions}
\label{tab:sumup-operators}

\end{table}
