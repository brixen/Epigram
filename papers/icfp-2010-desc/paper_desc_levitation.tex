\section{Levitating the Universe of Descriptions}
\label{sec:desc-levitate}

In this section, we will fulfil our promises and show how we implement
the signatures, first for the enumerations, and then for the codes of
the $\Desc$ universe.  Persuading this to perform was a perilous
pedagogical peregrination for the protagonist.  Our method was indeed to
hardwire constants implementing the signatures specified above, in the
first instance, but then attempt to replace them, step by step, with
\emph{definitions}: ``Is \(2+2\) still \(4\)?'', ``No, it's a loop!''.
But we did find a way, so now we hope to convey to the reader the
dizzy feeling of levitation, without the falling.



\subsection{Implementing finite enumerations}

\begin{wstructure}
<- Recall typing rules of 1st section
    -> Make clear they were just promises
    -> Can be implemented now
        <- Simply List UId
\end{wstructure}

In Section~\ref{sec:finite-sets}, we specified the
finite sets of tags. We are going to implement the $\EnumU$ type former and
its constructors. Recall:
%
\[\Type{\EnumU}\qquad\Bhab{\NilE}{\EnumU}\qquad
\Bhab{\ConsE{(\Bhab{\M{t}}{\UId})}{(\Bhab{\M{E}}{\EnumU})}}{\EnumU}
\]
%
The $\NilE$ and $\ConsE{\!}{\!}$ constructors are just the `nil' and
`cons' or ordinary lists, with elements from \(\UId\).
Therefore, we
implement:
%
\[
\EnumU \mapsto \Mu{(\ListD\: \UId)}
\qquad
\NilE \mapsto \ListNil
\qquad
\ConsE{\M{t}}{\M{E}} \mapsto \ListCons{\M{t}}{\M{E}}
\]


\begin{wstructure}
<- Consequences
    -> Type theory doesn't need to be extended with EnumU, NilE, and ConsE
        <- EnumU == Mu EnumUD
        <- NilE, ConsE are just tags
    -> Do not need a specific \spi eliminator
        <- \spi is an instance of the generic eliminator
            <- Code?
    -> Anything else remains the same (switch, EnumT, 0, 1+)
\end{wstructure}

Let us consider the consequences. We discover that the type
theory does not need to be extended with a special type former $\EnumU$,
or special constructors $\NilE$ and $\ConsE$. 
Moreover, the $\spi{\M{E}}{\M{P}}$ operator, computing tuple types
of \(\M{P}\)s by recursion on \(\M{E}\) need not be hardwired: we can
just use the generic $\F{ind}$ operator, as we would for any ordinary
program.

Note, however, that the universe decoder \(\EnumT{\M{E}}\) \emph{is}
hardwired, as are the primitive \(\Ze\) and \(\Su{\!}\) that
we use for low-level values, and indeed the \(\F{switch}\) operator.
We cannot dispose of data altogether! We have, however, gained
the ordinariness of the enumeration \emph{codes}, and hence of generic
programs which manipulate them. Our next step is similar: we are going to
condense the entire naming scheme of datatypes \emph{into itself}.

%% Apart from these changes, we are left with implementing the other
%% components of finite sets. This consists of $\EnumT$, $\Ze$, $\Su$, as
%% well as the $\F{switch}$ operator. Note that the actual implementation
%% of $\EnumU$ does not influence our implementation of $\EnumT$: be they
%% hard-coded or codes in the $\Desc$ universe, the $\EnumU$ objects
%% behave the same. We have witnessed this effect when carrying the
%% operation in Epigram, moving from an hard-coded presentation to a
%% self-hosted one. Absolutely no change to the $\EnumT$ objects was
%% required.

\begin{wstructure}
<- Summary of the operation
    <- The content of the type theory is exactly the same
        <- before == after
    /> type naming scheme condenses
        <- Replace named constructors by codes in the universe of datatypes
    -> Our next step is a similar move (in essence)
        /> Condenses the entire naming scheme of datatypes
\end{wstructure}

%In this section, we have replaced a low-level presentation of finite
%sets by a self-hosted one, expressed in the universe of
%descriptions. However, formally, the content of the type theory
%remains unchanged: objects that were present before the modification
%are still there. Conversely, we have not introduced any spurious
%object.

%If not on the content, this modification had an effect on the
%names. The type naming scheme of the type theory has condensed: named
%type formers ($\EnumU$) and constructors ($\NilE$ and $\ConsE$) are
%now replaced by codes and their fixpoint in the universe of
%descriptions. In essence,

\subsection{Implementing descriptions}

\begin{wstructure}
<- Realising our promises
    <- We are going to implement Desc
    /> Desc is itself a datatype
        <- Same situation as EnumU
            <- We want to benefit from generic operations
        -> It ought to be encoded in itself
\end{wstructure}

We shall now fulfil our implementation promises, encoding the universe
of descriptions. In and of itself, the codes, $\Desc$, is nothing but
a datatype. We are in the same situation as with $\EnumU$: we ought to
be able to describe the codes of $\Desc$ in $\Desc$ itself. Hence,
this code would be a first-class citizen, born with the standard,
generic equipment of datatypes.

\subsubsection{First attempt}

\begin{wstructure}
<- A partial implementation
    <- '1 and 'indx are easy
    <- 'sigma is partially doable
        /> lack the ability to do an higher-order inductive call
    -> Show partial code [figure]
\end{wstructure}

Our first attempt gets stuck quite quickly:
%
\[\stk{
\DescD : \Desc \\
\DescD \mapsto
  \tada{\stkm{\DUnit\\ \DSigma{\!}{\!}\\ \DIndx{\!}}}
       {\stkm{ \DUnit                                \\
         \DSigma{\Set}{(\LAM{\V{S}} \SHED)}      \\
         \DIndx{\DUnit}    }                    } \\
%\begin{array}{@{}ll}
%\DescD \mapsto \DSigma{\!}{\!} & (\EnumT{[ \DUnit, \DSigma{\!}{\!}, \DIndx{\!} ]})  \\
%                               & \left[\begin{array}{l}
%                                   \DUnit                                \\
%                                   \DSigma{\Set}{\LAM{\V{S}} \SHED}      \\
%                                   \DIndx{\DUnit}                        \\
%                                 \end{array}
%                                 \right]
%\end{array}
}\]
%
Let us explain where we stand. Much as
we have done so far, we first offer a constructor choice from
$\DUnit$, $\DSigma{\!}{\!}$, and $\DIndx{\!}$. The reader will notice
that the `tagged' notation we have used for the $\Desc$ constructors now
fully makes sense: these were actually the tags we are defining.
For $\DUnit$, we immediately reach the end of the description. For
$\DIndx{\!}$, there is a single recursive argument. Describing
$\DSigma{\!}{\!}$ is problematic. Recall the specification of
$\DSigma{\!}{\!}$:
%
\[
\DSigma{(\Bhab{\V{S}}{\Set})}{(\Bhab{\V{D}}{\V{S} \To \Desc})} : \Desc\\
\]
%
So, we first pack a  $\Set$, $\V{S}$. We should then like
a recursive argument \emph{indexed} by $\V{S}$, but
that is an \emph{exponential}, and our presentation is entirely
first-order so far, delivering only sums-of-products. To code our
universe, we must first enlarge it!


\subsubsection{Second attempt}

\begin{wstructure}
<- Extending the universe of description
    -> With higher-order induction
    <- Intuition: index elements in X by H, and go on reading
        -> indx is isomorph to hindx for H = 1
    /> Keep indx
        <- First order!
        -> Extensionally equal to hindx 1
        /> Practically, definitional equality on Sigma/Pi cannot cope with it
    -> Show DescD code
\end{wstructure}

In order to capture a notion of higher-order induction, we add a code
$\DHindx{\!}{\!}$ that takes an indexing set $\V{H}$. Intuitively,
$\DHindx{\!}{\!}$ gives a recursive subobject for each element of $H$.
%
\[\stk{
    \DHindx{(\Bhab{\M{H}}{\Set})}{(\Bhab{\M{D}}{\Desc})} : \Set \smallskip \\
\descop{\DHindx{\V{H}}{\V{D}}}{\V{X}}     \mapsto \TIMES{(\V{H} \To \V{X})}{\descop{\V{D}}{\V{X}}} \\
}\]


Note that up to isomorphism, $\DIndx{\!}$ is subsumed by
$\DHindx{\Unit}{\!}$. However, the apparent duplication has some
value.  Unlike its counterpart, $\DIndx{\!}$ is first-order: we prefer
not to demand dummy functions from \(\Unit\) in ordinary data,
e.g. \(\NatSuc{(\LAM{\_}n)}\). It is na{\"\i}ve to imagine that up to
isomorphism, any representation of data will do.  First-order
representations are finitary by construction, and thus admit a richer,
componentwise decidable equality than functions may in
general possess.\footnote{E.g., extensionally, there is one inhabitant of
\(\EnumT{\void}\To\Nat\); intensionally, there is a countable infinitude
which it is not safe to collapse.}

We are now able to describe our universe of datatypes:
%
\[\stk{
\DescD : \Desc \\
\DescD \mapsto\tada
{\stkm{ \DUnit\\ \DSigma{\!}{\!}\\ \DIndx{\!}\\ \DHindx{\!}{\!}}}
{\stkm{
\DUnit                                            \\
                                   \DSigma{\Set}{\LAM{\V{S}} \DHindx{\V{S}}{\DUnit}}   \\
                                   \DIndx{\DUnit}                                    \\
                                   \DSigma{\Set}{\LAM{\_} \DIndx{\DUnit}}
}}
}\]
%
The $\DUnit$ and $\DIndx{\!}$ cases remain unchanged, as expected. We
successfully describe the $\DSigma{\!}{}$ case, by a simple appeal to
the higher-order induction on $\V{S}$. The $\DHindx{\!}{\!}$ case
consists in packing a $\Set$ with a recursive argument.

At a first glance, we have achieved our goal. We have described the
codes of the universe of descriptions. Taking the fixpoint of \(\descop{\DescD}\)
gives us a datatype exactly like $\Desc$. Might we be
so bold as to take \(\Desc \mapsto \Mu{\DescD}\) as the levitating
definition? If we do, we shall come down with a bump! 
To complete our levitation, just as in the magic trick, requires
hidden assistance. Let us explain the problem and reveal the `invisible
cable' which fixes it.


\subsubsection{Final move}

\begin{wstructure}
<- Subtlety: translation of [ ... ]
    -> Let us do it manually
        -> Code with problem for the motive of switch
\end{wstructure}

The definition \(\Desc \mapsto \Mu{\DescD}\) is circular,
but the offensive recursion is concealed by a prestidigitation.
Expanding be \(\toDesc{-}\) and propagating types as in
Figure~\ref{fig:type-checking} reveals the
awful truth:
\[
\Desc\mapsto
\Mu{\stk{(\DSigma{\EnumT{\sqr{ \DUnit\: \DSigma{\!}{\!}\: \DIndx{\!}\: 
    \DHindx{\!}{\!}}}\\}
    {\;\F{switch}\:\sqr{ \DUnit\: \DSigma{\!}{\!}\: \DIndx{\!}\: 
    \DHindx{\!}{\!}}\:(\LAM{\_}\Desc)\\
\;\sqr{\stkm{
\DUnit                                            \\
                                   \DSigma{\Set}{\LAM{\V{S}} \DHindx{\V{S}}{\DUnit}}   \\
                                   \DIndx{\DUnit}                                    \\
                                   \DSigma{\Set}{\LAM{\_} \DIndx{\DUnit}}
}}})}}
\]
The recursion shows up only because we must specify the return type
of the general-purpose \(\F{switch}\), and it is computing a \(\Desc\)!
Although type propagation
allows us to hide this detail \emph{when defining a function}, we cannot
readily suppress this information and check types
when \(\F{switch}\) is fully applied.

\begin{wstructure}
<- The magician trick
    <- Our problem is to give a motive for switch
        /> We perfectly know what it ought to be: \_ -> DescD
    -> Solution: extend the type theory with a special purpose switchD
        -> Only extension required to the type theory!
        -> Hidden away to the user by the syntactic sugar
            -> Sufficient to ensure unavailability as a raw operator
            <- Another instance of type propagation
\end{wstructure}

%What happens if we unfold the definition? We ought to build the following term:
%
%\[
%\PLAM{\V{x}}{(\EnumT{\V{E}})} \switch{\V{E}}{(\LAM{\_} %\Mu{\DescD})}{\V{\pi^f}}{\V{x}}
%\]
%
%But this is quite problematic. We are still in the process of
%constructing $\DescD$, and the motive of $\F{switch}$ is abruptly
%begging for this very same $\DescD$. Despite our willingness, we
%cannot materialise such motive. However, we perfectly know what the
%motive is.

We are too close to give up now. If only we did not need to
supply that return type, especially when we know what it must be.
We eliminate the recursion by \emph{specialising} \(\F{switch}\):
%
\[
\F{switchD} : \PITEL{\V{E}}{\EnumU}   \To
                (\spi{\V{E}}{\LAM{\_} \Desc}) \To
                \EnumT{\V{E}} \To \Desc
\]
%
The magician's art rests here, in this extension. We conceal it
behind a type propagation rule for \(\F{switchD}\) which we apply
with higher priority than for \(\F{switch}\) in general.
%
\[
\Rule{\Gamma \Vdash
  \propag{\push{\sqr{\vec{t}}}{\spi{\M{E}}{(\PLAM{x}{\EnumT{E}}\Desc)}}}
                           {\M{t'}}}
     {\Gamma \Vdash
\propag{\push{\sqr{\vec{t}}}{\EnumT{\M{E}}\To\Desc}}
 {\switchD{\M{E}}{\M{t'}}}}
\]
As a consequence, our definition above now propagates without
introducing recursion. Of course, by pasting together
the declaration of \(\Desc\) and its internal copy, we have made
it appear in its own type. Hardwired as a \emph{fait accompli},
this creates no regress, although one must assume the definition
to recheck it.

\begin{wstructure}
<- Generic programming now!
    <- Desc is just data
        -> Can be manipulated
    <- Free induction scheme on Desc
        -> Ability to inspect datatypes
        -> Ability to program on datatypes
\end{wstructure}


We have levitated \(\Desc\). Beyond its pedagogical value, this
exercise has several practical outcomes. First of all, it reveals that
the $\Desc$ universe is just plain data. As any piece of data, it can
therefore be inspected and manipulated. Moreover, it is expressed in
the $\Desc$ universe. As a consequence, it is equipped, for free, with
an induction principle. So, our ability to inspect and program with
$\Desc$ is not restricted to a meta-language: we now have all the
necessary equipment in the theory to \emph{program} over
datatypes. \emph{Generic programming is just
  programming}.


\subsection{The generic catamorphism}

\begin{wstructure}
<- Making cata
    <- Present the type signature
    <- Starts with a call to generic induction
        <- induction on Desc!
        /> Show types at hand
        -> Explain how to use inductive hypothesis
    <- Implement the 'replace' function
    -> Dependent-typeless catamorphism 
\end{wstructure}

In Section~\ref{sec:desc-fix-point}, we hardwired a dependent
$\F{ind}$unction principle, instead of the catamorphism. However, in
some circumstances, the full power of a dependent elimination is not
necessary. Let us now derive the catamorphism
from $\F{ind}$ principle.

\newcommand{\cata}{\F{cata}}

The catamorphism is defined by induction on the description $\V{D}$,
with a readily propagated non-dependent return type $\V{T}$.
Given a node $\V{xs}$
and the induction hypotheses, the method ought to build an element of
$\V{T}$. Provided that we know how to make an element of
$\descop{\V{D}}{\V{T}}$, this step will be performed by the algebra
$\V{f}$. Let us take a look at this jigsaw:
%
\[\stk{
\cata : \PITEL{\V{D}}{\Desc}
           \PI{\V{T}}{\Set}
           (\descop{\V{D}}{\V{T}} \To \V{T}) \To 
           \Mu{\V{D}} \To \V{T} \\
\cata\: \V{D}\: \V{T}\: \V{f} \mapsto
  \sind \LAM{\V{xs}}\LAM{\V{hs}} \V{f}\: \SHED
}\]
%
We are left with filling the hole. Recall that we have
\(\Bhab{\V{xs}}{\descop{\V{D}}{\Mu{\V{D}}}}\) and
\(\Bhab{\V{hs}}{\All{\V{D}}{(\Mu{\V{D}})}{(\LAM{\_} \V{T})}{\V{xs}}}\)
at hand. Our goal is to make an element of
\(\descop{\V{D}}{\V{T}}\). Intuitively, $\V{xs}$ is of the right
shape, but its sub-elements are of the wrong type. On the other hand,
for each sub-element of $\V{xs}$, $\V{hs}$ gives us the corresponding
element in $\V{T}$.  Therefore, to construct an element of
\(\descop{\V{D}}{\V{T}}\), we must replace the recursive components of
\(\V{xs}\) by their counterparts from \(\V{hs}\). Let us write a
program to do that---please forgive us if we lapse to a pattern matching
notation, for readability's sake.
%
\[\stk{
\F{replace} : \stk{\PITEL{\V{D}}{\Desc}
                   \PITEL{\V{X},\V{Y}}{\Set}\\
                   \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
                   \All{\V{D}}{\V{X}}{(\LAM{\_}\V{Y})}{\V{xs}} \To
                   \descop{\V{D}}{\V{Y}}} \\
\F{replace}\: \DUnit\:          \V{X}\: \V{Y}\: \Void\:          \Void          \mapsto 
    \Void                                                                                                         \\
\F{replace}\: (\DSigma{\V{S}}{\V{D}})\: \V{X}\: \V{Y}\: \pair{\V{s}}{\V{d}}{}\: \V{d'}             \mapsto
    \pair{\V{s}}{\F{replace}\: (\V{D}\: \V{s})\: \V{X}\: \V{Y}\: \V{d}\: \V{d'}}{}                                \\
\F{replace}\: (\DIndx{\V{D}})\:     \V{X}\: \V{Y}\: \pair{\V{x}}{\V{d}}{}\: \pair{\V{y}}{\V{d'}}{} \mapsto        \\
\qquad  \pair{\V{y}}{\F{replace}\: \V{D}\: \V{X}\: \V{Y}\: \V{d}\: \V{d'}}{}                                      \\
\F{replace}\: (\DHindx{\V{H}}{\V{D}})\: \V{X}\: \V{Y}\: \pair{\V{f}}{\V{d'}}{}\: \pair{\V{g}}{\V{d'}}{} \mapsto   \\
\qquad  \pair{\V{g}}{\F{replace}\: \V{D}\: \V{X}\: \V{Y}\: \V{d}\: \V{d'}}{}
}\]
%
Filling the hole in $\F{cata}$ with \(\F{replace}\: \V{D}\:
(\Mu{\V{D}})\: \V{T}\: \V{xs}\: \V{hs}\) closes the problem. In the
type theory, we have built a generic catamorphism. Any datatype will
now come equipped with this operation, for free.

%% The astute reader will have been struck by the type of $\F{replace}$:
%% it is \emph{almost} the morphism part -- sometimes called \emph{map}
%% -- of the functor $\V{D}$ from $\V{X}$ to $\V{Y}$ in $\Set$. Just as
%% the $\F{induction}$ is the dependent version of $\cata$, $\F{replace}$
%% is the dependent version of the map, which uses the induction
%% hypotheses. For space reason, we will not present the non-dependent
%% map. It can be found in the Agda model.

\begin{wstructure}
<- Deriving generic functions
    <- Taking a Desc and computing a function
        <- Desc comes equipped with an induction principle
        -> Ability to compute more functions from it
            -> More generic functions
    <- Inspecting datatypes
        <- All described byu a Desc code
        -> Ability to explore the code
            <- Desc equipped with an induction principle
            -> Build new objects based on that structure
\end{wstructure}

With this example, we have shown how we can derive a generic
operation, the catamorphism, from a pre-existing generic operation,
the induction principle. This has been made possible by our ability to
manipulate descriptions as first-class objects: the catamorphism is,
basically, a function mapping a $\Desc$ to a datatype specific
operation. This is a form of polytypic programming, as we learned from
PolyP~\cite{jansson:polyp}.

%% Moreover, the $\F{replace}$ function demonstrates the benefit of an
%% approach based on universes. The datatypes living in the universe of
%% descriptions, we are able to \emph{inspect} them. As shown by
%% $\F{replace}$, it is easy to explore these structures, as well as
%% building new ones.

\subsection{The generic free monad}
\label{sec:desc-free-monad}

\begin{wstructure}
<- A generic program: the free monad construction
    <- Recall free monad construction in Haskell
        -> Based on a functor F
    <- Note that the free monad construction is itself defined by a functor
        -> Extract it
\end{wstructure}

In this section, we will turn to a more ambitious generic operation on
datatype. Given a functor, represented as a tagged description, we
build the free monad over this functor.

\newcommand{\FMFreeMonad}{\D{FreeMonad}}
\newcommand{\FMFreeMonadD}{\D{FreeMonadD}}
\newcommand{\FMVar}{\C{Var}}
\newcommand{\FMComposite}{\C{Composite}}

Let us recall the free monad construction. Given a functor $F$, the
free monad over $F$ is defined by the following datatype:
%
\[
\stk{
\data \FMFreeMonad\: \PITEL{\V{F}}{\Set \To \Set} 
                     \PITEL{\V{X}}{\Set} :
                     \Set 
\where \\
\;\;\begin{array}{@{}l@{\::\:\:}l@{\quad}l}
    \FMVar           & \V{X} \To \FMFreeMonad\: \V{F}\: \V{X}                            \\
    \FMComposite     & \V{F} (\FMFreeMonad\: \V{F}\: \V{X}) \To \FMFreeMonad\: \V{F}\: \V{X}    
\end{array}
}
\]
%
Being an inductive type, this $\FMFreeMonad$ datatype is itself
defined by a pattern functor. It is given by:
%
\[
\FMFreeMonadD\: \V{F}\: \V{X}\: \V{Z} \mapsto \V{X} \mathop{\D{+}} \V{F} \V{Z}
\]

\begin{wstructure}
    <- Encode it in the Desc world [equation]
        <- F is the Desc we start with
        <- The free monad functor is what we have just defined
        <- [\_]* : Desc -> Set -> Desc
           [\_]* D X = 'cons ['var ('sigma X (\_ -> '1))] D
        -> Mu does the fixpoint
\end{wstructure}

In our setting, the free monad construction will take the functor as a
tagged description, a set $\V{X}$ of variables, and will compute the
tagged description of the corresponding free monad. Implementing this
function is surprisingly easy:
%
\[\stk{
\FreeMonad{\_} : \TagDesc \To \Set \To \TagDesc \\
\FreeMonad{\pair{\V{E}}{\V{D}}{}}\:\V{X} \mapsto
    \pair{\pair{\DVar{}}{\V{E}}{}}
         {\pair{\DSigma{\V{X}}{\DUnit}}{\V{D}}{}}{}
}\]
%
We simply add a constructor, $\DVar{\!}$, and define its argument to
be a $\DSigma{\V{X}}{\DUnit}$, that is an element of $\V{X}$. We keep
$\V{E}$ and $\V{D}$ as they were, hence leaving the other constructors
unchanged. Unfolding the interpretation of this definition, we
convince ourselves that this corresponds to the functor
$\FMFreeMonadD$. The fixpoint operation ties the knot and gives us
the full-blown free monad construction.

\begin{wstructure}
<- A generic program: monadic substitution [equation]
    <- subst : \forall T X Y. mu ([T]* X) -> (X -> mu ([T]* Y)) -> mu ([T]* Y)
        -> Using Fold
\end{wstructure}

Of course, we must equip the resulting datatypes with operations
delivering a monadic interface. As expected, \(\LAM{\x}\DVar{\x}\)
plays the r\^ole of \return, embedding variables into terms. The
\bind\ operation corresponds to \emph{substitution}. We will now
implement it, as a generic function.


\newcommand{\subst}{\F{subst}}
\newcommand{\apply}{\F{apply}}

Our implementation will appeal to the $\cata$ function developed
previously. So, let us write down the types, and fill as much
arguments to $\cata$ as possible:
%
\[\stk{
\begin{array}{@{}ll}
\subst : & \PITEL{\V{D}}{\TagDesc}
           \PI{\V{X}, \V{Y}}{\Set} 
           (\V{X} \To \Mu{(\toDesc{(\FreeMonad{\V{D}}{\V{Y}})})}) \To \\
         & \Mu{(\toDesc{(\FreeMonad{\V{D}}{\V{X}})})} \To
           \Mu{(\toDesc{(\FreeMonad{\V{D}}{\V{Y}})})} 
\end{array} \\
\subst\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma} \mapsto
  \cata\: (\toDesc{(\FreeMonad{\V{D}}{\V{X}})})\: 
          (\Mu{(\toDesc{(\FreeMonad{\V{D}}{\V{Y}})})})\: 
          \SHED
}\]
%
We are left with implementing the algebra of the
catamorphism. Intuitively, its role is to catch appearances of
$\DVar{\V{x}}$ and replace them by $\V{\sigma}\: \V{x}$. This
corresponds to the following definition:
%
\[\stk{
\begin{array}{@{}ll}
\apply : & \PITEL{\V{D}}{\TagDesc} 
           \PI{\V{X}, \V{Y}}{\Set} 
           (\V{X} \To \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{X}}})}) \To \\
         & \descop{\toDesc{\FreeMonad{\V{D}}{\V{X}}}}{\Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}} \To
           \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}
\\
\end{array} \\
\begin{array}{@{}l@{\:\mapsto\:\:}l}
\apply\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma}\: \pair{\DVar{\!}}{\V{x}}{}   & \V{\sigma}\: \V{x}                   \\
\apply\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma}\: \pair{\V{c}}{\V{xs}}{} & \Con{\pair{\V{c}}{\V{xs}}{}}
\end{array}
}\]

\begin{wstructure}
    -> Consequences
        <- We have free monad datatype
            <- Term + variables
        <- We have monad operations
            <- Return / var
            <- Substitution / bind
\end{wstructure}

Filling the sub-goal with $\apply\: \V{D}\: \V{X}\: \V{Y}\:
\V{\sigma}$ completes the implementation. To sum up, we have
implemented the free monad construction for an arbitrary tagged
description. This gives the developer the ability, for any datatype,
to extend it with a notion of variable. Then, we have equipped this
structure with the corresponding monadic operation, \bind\ and
\return. This construction is an example of type-indexed
datatype~\cite{hinze:generic-haskell}, as found in Generic Haskell:
from a datatype, we build a new datatype and equip it with its
structure.

\begin{wstructure}
<- Deriving new data-structure and functions on them
    <- Computing the Free Monad of a datatype
        <- Derive new data-structure from previous one
            <- It is just code
        /> New data-structure comes with some equipment
    <- Computing new functions on computed datatypes
        <- If data comes with structure, we ought to be able to capture it
            <- Induction on Desc
            -> Ability to compute over data
\end{wstructure}

%% Candidate for removal:
%% With the free monad construction, we have seen two kinds of generic
%% operations. Firstly, we have derived a new data-structure from another
%% one: we make the free monad from its underlying functor. To do so, we
%% crucially rely on the fact that datatypes are nothing but codes. We
%% are therefore entitled to modify this code and, in this case, extend
%% it. Extending a datatype might give rise to a more structured object,
%% as was the case here.  So, secondly, we have equipped this new
%% datatype with its inherent structure: the \bind\ and
%% \return\ operations. We have been able to build them as generic
%% functions.
