\section{Levitating the Universe of Descriptions}
\label{sec:desc-levitate}

In this section, we will fulfil our promises and show how we implement
the signatures, first for the enumerations, and then for the codes of
the $\Desc$ universe.  Persuading this to perform was a perilous
pedagogical peregrination for the protagonist.  Our method was indeed to
hardwire constants implementing the signatures specified above, in the
first instance, but then attempt to replace them, step by step, with
\emph{definitions}: ``Is \(2+2\) still \(4\)?'', ``No, it's a loop!''.
But we did find a way, so now we hope to convey to the reader the
dizzy feeling of levitation, without the falling.



\subsection{Implementing finite enumerations}

\begin{wstructure}
<- Recall typing rules of 1st section
    -> Make clear they were just promises
    -> Can be implemented now
        <- Simply List UId
\end{wstructure}

In Section~\ref{sec:finite-sets}, we specified the
finite sets of tags. We are going to implement the $\EnumU$ type former and
its constructors. Recall:
%
\[\Type{\EnumU}\qquad\Bhab{\NilE}{\EnumU}\qquad
\Bhab{\ConsE{(\Bhab{\M{t}}{\UId})}{(\Bhab{\M{E}}{\EnumU})}}{\EnumU}
\]
%
The $\NilE$ and $\ConsE{\!}{\!}$ constructors are just the `nil' and
`cons' or ordinary lists, with elements from \(\UId\).
Therefore, we
implement:
%
\[
\EnumU \mapsto \Mu{(\ListD\: \UId)}
\qquad
\NilE \mapsto \ListNil
\qquad
\ConsE{\M{t}}{\M{E}} \mapsto \ListCons{\M{t}}{\M{E}}
\]


\begin{wstructure}
<- Consequences
    -> Type theory doesn't need to be extended with EnumU, NilE, and ConsE
        <- EnumU == Mu EnumUD
        <- NilE, ConsE are just tags
    -> Do not need a specific \spi eliminator
        <- \spi is an instance of the generic eliminator
            <- Code?
    -> Anything else remains the same (switch, EnumT, 0, 1+)
\end{wstructure}

Let us consider the consequences. We discover that the type
theory does not need to be extended with a special type former $\EnumU$,
or special constructors $\NilE$ and $\ConsE$. 
Moreover, the $\spi{\M{E}}{\M{P}}$ operator, computing tuple types
of \(\M{P}\)s by recursion on \(\M{E}\) need not be hardwired: we can
just use the generic $\F{ind}$ operator, as we would for any ordinary
program.

Note, however, that the universe decoder \(\EnumT{\M{E}}\) \emph{is}
hardwired, as are the primitive \(\Ze\) and \(\Su{-}\) constructs that
we use for low-level values, and indeed the \(\F{switch}\) operator.
We cannot dispose of data altogether! We have, however, gained
the ordinariness of the enumeration \emph{codes}, and hence of
programs which manipulate them. Our next step is similar: we are going to
condense the entire naming scheme of datatypes \emph{into itself}.

%% Apart from these changes, we are left with implementing the other
%% components of finite sets. This consists of $\EnumT$, $\Ze$, $\Su$, as
%% well as the $\F{switch}$ operator. Note that the actual implementation
%% of $\EnumU$ does not influence our implementation of $\EnumT$: be they
%% hard-coded or codes in the $\Desc$ universe, the $\EnumU$ objects
%% behave the same. We have witnessed this effect when carrying the
%% operation in Epigram, moving from an hard-coded presentation to a
%% self-hosted one. Absolutely no change to the $\EnumT$ objects was
%% required.

\begin{wstructure}
<- Summary of the operation
    <- The content of the type theory is exactly the same
        <- before == after
    /> type naming scheme condenses
        <- Replace named constructors by codes in the universe of datatypes
    -> Our next step is a similar move (in essence)
        /> Condenses the entire naming scheme of datatypes
\end{wstructure}

%In this section, we have replaced a low-level presentation of finite
%sets by a self-hosted one, expressed in the universe of
%descriptions. However, formally, the content of the type theory
%remains unchanged: objects that were present before the modification
%are still there. Conversely, we have not introduced any spurious
%object.

%If not on the content, this modification had an effect on the
%names. The type naming scheme of the type theory has condensed: named
%type formers ($\EnumU$) and constructors ($\NilE$ and $\ConsE$) are
%now replaced by codes and their fixpoint in the universe of
%descriptions. In essence,

\subsection{Implementing descriptions}

\begin{wstructure}
<- Realising our promises
    <- We are going to implement Desc
    /> Desc is itself a datatype
        <- Same situation as EnumU
            <- We want to benefit from generic operations
        -> It ought to be encoded in itself
\end{wstructure}

We shall now fulfil our implementation promises, delivering the
codes of the universe of descriptions. In and by itself,
the codes, $\Desc$, is nothing but a datatype. We are in the same
situation as with $\EnumU$: we ought to be able to describe the codes
of $\Desc$ in $\Desc$ itself. Hence, this code would be a first-class
citizen, born with the standard, generic equipment of datatypes.

\subsubsection{First attempt}

\begin{wstructure}
<- A partial implementation
    <- '1 and 'indx are easy
    <- 'sigma is partially doable
        /> lack the ability to do an higher-order inductive call
    -> Show partial code [figure]
\end{wstructure}

Our first attempt is the following:
%
\[\stk{
\DescD : \Desc \\
\begin{array}{@{}ll}
\DescD \mapsto \DSigma{\!}{\!} & (\EnumT{[ \DUnit, \DSigma{\!}{\!}, \DIndx{\!} ]})  \\
                               & \left[\begin{array}{l}
                                   \DUnit                                \\
                                   \DSigma{\Set}{(\LAM{\V{S}} \SHED)}      \\
                                   \DIndx{\DUnit}                        \\
                                 \end{array}
                                 \right]
\end{array}
}\]
%
Let us explain how we have proceeded and the obstacle we face. Much as
the datatypes we have seen so far, we first choose a constructor among
$\DUnit$, $\DSigma{\!}{\!}$, and $\DIndx{\!}$. The reader will notice
that the tagged notation we have used for the $\Desc$ constructors now
fully makes sense: these were actually the tags we are defining.

For $\DUnit$, we immediately reach the end of the description. For
$\DIndx{\!}$, there is a single recursive argument. Describing
$\DSigma{\!}{\!}$ is problematic. Recall the specification of
$\DSigma{\!}{\!}$:
%
\[    \DSigma{\!}{\!} : \PI{\V{S}}{\Set} \PIS{\V{S} \To \Desc} \Desc      \]
%
So, we first pack an element $\V{S}$ of $\Set$. Then, we would like to
express a notion of recursive argument \emph{indexed} by $\V{S}$. Because
our presentation is entirely first-order so far, we are not able to
express this notion. We shall remedy to this situation.


\subsubsection{Second attempt}

\begin{wstructure}
<- Extending the universe of description
    -> With higher-order induction
    <- Intuition: index elements in X by H, and go on reading
        -> indx is isomorph to hindx for H = 1
    /> Keep indx
        <- First order!
        -> Extensionally equal to hindx 1
        /> Practically, definitional equality on Sigma/Pi cannot cope with it
    -> Show DescD code
\end{wstructure}

In order to capture a notion of higher-order induction, we need to
extend our universe of descriptions. This consists in adding a code
$\DHindx{\!}{\!}$ that takes an indexing set $\V{H}$. Intuitively,
$\DHindx{\!}{\!}$ uses the elements of $H$ to index as many recursive
arguments:
%
\[\stk{
\begin{array}{ll}
\stk{
\data \Desc : \Set \where \\
\;\;\begin{array}{@{}l@{\::\:\:}l@{\quad}l}
    \DHindx{\!}{\!} & \PI{\V{H}}{\Set} \Desc \To \Desc \\
    \ldots          & \:\:\ldots
\end{array}
}
\vspace{0.2in}
\\
\stk{
\descop{\_\:}{} : \Desc \To \Set \To \Set \\
\begin{array}{@{}l@{\:=\:\:}ll}
\descop{\DHindx{\V{H}}{\V{D}}}{\V{X}}     &  \TIMES{(\V{H} \To \V{X})}{\descop{\V{D}}{\V{X}}} \\
\ldots                                    &  \ldots 
\end{array}
}
\end{array}
}\]


Note that $\DIndx{\!}$ is isomorphic to $\DHindx{\Unit}{\!}$. However,
we tolerate this duplication. Indeed, unlike its counterpart,
$\DIndx{\!}$ is first-order. Both codes are \emph{extensionally} the
same but, in practice, they will be dealt with rather
differently. While definitional equality can cope with first-order
objects, the functional presentation introduced by $\DHindx{\!}{}$ is
unlikely to be amenable to a purely definitional treatment.

We are now able to describe our universe of datatypes:
%
\[\stk{
\DescD : \Desc \\
\begin{array}{@{}ll}
\DescD \mapsto \DSigma{\!}{\!} & (\EnumT{[ \DUnit, \DSigma{\!}{\!}, \DIndx{\!}, \DHindx{\!}{\!} ]}) \\
                           & \left[\begin{array}{l}
                                   \DUnit                                            \\
                                   \DSigma{\Set}{(\LAM{\V{S}} \DHindx{\V{S}}{\DUnit})}   \\
                                   \DIndx{\DUnit}                                    \\
                                   \DSigma{\Set}{(\LAM{\V{H}} \DIndx{\DUnit})}
                                   \end{array}
                             \right]
\end{array}
}\]
%
The $\DUnit$ and $\DIndx{\!}$ cases remain unchanged, as expected. We
successfully describe the $\DSigma{\!}{}$ case, by a simple appeal to
the higher-order induction on $\V{S}$. The $\DHindx{\!}{\!}$ case
consists in packing an $\V{H}$ in $\Set$ with a recursive argument.

At a first glance, we have achieved our goal. We have described the
codes of the universe of description. Taking the fixpoint of this
object gives us $\Desc$, up to isomorphism. We have implemented the
codes of datatypes as an object levitating inside itself. However,
this levitation operation, just as any magic trick, relies on an
invisible cable. Let us reveal it, hence finishing our implementation.


\subsubsection{Final move}

\begin{wstructure}
<- Subtlety: translation of [ ... ]
    -> Let us do it manually
        -> Code with problem for the motive of switch
\end{wstructure}


Our reader might be slightly confused to learn that the trick is
visible in the definition of $\DescD$. Or rather, it is made invisible
by careful usage of type propagation. Indeed, let us try to elaborate
this term down to the low-level type theory. The $\EnumT{[ \ldots ]}$
construct elaborates to a finite set $\V{E}$ in $\EnumU$, inhabited by
the codes. Then, we can type-check the case definition, between square
brackets $[ \ldots ]$. This term $\V{f}$ is pushed into the type
$\EnumT{\V{E}} \To \Mu{\DescD}$. This corresponds to a finite function
definition, as presented in Figure~\ref{fig:type-checking}.


\begin{wstructure}
<- The magician trick
    <- Our problem is to give a motive for switch
        /> We perfectly know what it ought to be: \_ -> DescD
    -> Solution: extend the type theory with a special purpose switchD
        -> Only extension required to the type theory!
        -> Hidden away to the user by the syntactic sugar
            -> Sufficient to ensure unavailability as a raw operator
            <- Another instance of type propagation
\end{wstructure}

What happens if we unfold the definition? We ought to build the following term:
%
\[
\PLAM{\V{x}}{(\EnumT{\V{E}})} \switch{\V{E}}{(\LAM{\_} \Mu{\DescD})}{\V{\pi^f}}{\V{x}}
\]
%
But this is quite problematic. We are still in the process of
constructing $\DescD$, and the motive of $\F{switch}$ is abruptly
begging for this very same $\DescD$. Despite our willingness, we
cannot materialise such motive. However, we perfectly know what the
motive is. Consequently, we extend the type theory with a
special-purpose operator:
%
\[
\begin{array}{@{}ll}
%% switchD
\F{switchD} : & \PITEL{\V{e}}{\EnumU}               
                \PITEL{\V{b}}{\spi{\V{e}}{\LAM{\_} \Desc}}
                \PITEL{\V{x}}{\EnumT{\V{e}}} \To \Desc
\end{array}
\]
%
The entire work of the magician stands here, in this extension. Note
that the developer do not have to chose between the two variants of
$\F{switch}$. This is dealt with by the type propagation system
(Fig.~\ref{fig:type-checking}), extended with the following inference
rule:
%
\[
\Rule{\Gamma \Vdash \propag{\push{\V{t}}{\spiD{\V{e}}}}
                           {\V{t'}}}
     {\Gamma \Vdash \propag{\push{\V{t}}{\EnumT{\V{e}} \To \Desc}}
                           {\PLAM{\V{x}}{(\EnumT{\V{e}})} \switchD{\V{e}}{\V{t'}}{\V{x}}}
     }\;\mbox{$\V{t}$ is $[]$ or $[\_,\_]$}
\]

\begin{wstructure}
<- Generic programming now!
    <- Desc is just data
        -> Can be manipulated
    <- Free induction scheme on Desc
        -> Ability to inspect datatypes
        -> Ability to program on datatypes
\end{wstructure}


This concludes our levitation work. Beyond its pedagogical value, this
exercise has several practical outcomes. First of all, it reveals that
the $\Desc$ universe is just plain data. As any piece of data, it can
therefore be inspected and manipulated. Moreover, it is expressed in
the $\Desc$ universe. As a consequence, it is equipped, for free, with
an induction principle. So, our ability to inspect and program with
$\Desc$ is not restricted to the meta-language: we now have all the
necessary equipment in the target language to \emph{program} over
datatypes. In this setting, \emph{generic programming is just
  programming}.


\subsection{The generic catamorphism}

\begin{wstructure}
<- Making cata
    <- Present the type signature
    <- Starts with a call to generic induction
        <- induction on Desc!
        /> Show types at hand
        -> Explain how to use inductive hypothesis
    <- Implement the 'replace' function
    -> Dependent-typeless catamorphism 
\end{wstructure}

In Section~\ref{sec:desc-fix-point}, we have implemented a dependent
$\F{induction}$ principle, instead of the catamorphism. However, in
some circumstances, the full-power of a dependent elimination is not
necessary. In the following, we propose to derive the catamorphism
from the $\F{induction}$ principle.

\newcommand{\cata}{\F{cata}}

The catamorphism is defined by induction on the description $\V{D}$,
with a non-dependent motive targeting $\V{T}$. Given a node $\V{xs}$
and the induction hypotheses, the method ought to build an element of
$\V{T}$. Provided that we know how to make an element of
$\descop{\V{D}}{\V{T}}$, this step will be performed by the algebra
$\V{f}$. Let us take a look at this jigsaw:
%
\[\stk{
\cata : \PITEL{\V{D}}{\Desc}
           \PI{\V{T}}{\Set}
           (\descop{\V{D}}{\V{T}} \To \V{T}) \To 
           \Mu{\V{D}} \To \V{T} \\
\cata\: \V{D}\: \V{T}\: \V{f\: \V{x}} \mapsto
  \F{induction}\: \V{D}\:\V{x}\: (\LAM{\_}\V{T})\: (\LAM{\V{xs}\:\V{hs}} \V{f}\: \SHED)
}\]
%
We are left with filling the hole. Recall that we have
\(\Bhab{\V{xs}}{\descop{\V{D}}{\Mu{\V{D}}}}\) and
\(\Bhab{\V{hs}}{\All{\V{D}}{(\Mu{\V{D}})}{(\LAM{\_} \V{T})}{\V{xs}}}\)
at hand. Our goal is to make an element of
\(\descop{\V{D}}{\V{T}}\). Intuitively, $\V{xs}$ is of the right
shape, but its sub-elements are of the wrong type. On the other hand,
for each sub-element of $\V{xs}$, $\V{hs}$ gives us the corresponding
element in $\V{T}$.  Therefore, to construct an element of
\(\descop{\V{D}}{\V{T}}\), we replace the recursive components of
\(\V{xs}\) by their counterpart in \(\V{hs}\):
%
\[\stk{
\F{replace} : \stk{\PITEL{\V{D}}{\Desc}
                   \PITEL{\V{X},\V{Y}}{\Set}\\
                   \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
                   \All{\V{D}}{\V{X}}{(\LAM{\_}\V{Y})}{\V{xs}} \To
                   \descop{\V{D}}{\V{Y}}} \\
\F{replace}\: \DUnit\:          \V{X}\: \V{Y}\: \Void\:          \Void          \mapsto 
    \Void                                                                                                         \\
\F{replace}\: (\DSigma{\V{S}}{\V{D}})\: \V{X}\: \V{Y}\: \pair{\V{s}}{\V{xs}}{}\: \V{ys}             \mapsto
    \pair{\V{s}}{\F{replace}\: (\V{D}\: \V{s})\: \V{X}\: \V{Y}\: \V{xs}\: \V{ys}}{}                                 \\
\F{replace}\: (\DIndx{\V{D}})\:     \V{X}\: \V{Y}\: \pair{\V{x}}{\V{xs}}{}\: \pair{\V{y}}{\V{ys}}{} \mapsto       \\
\qquad  \pair{\V{y}}{\F{replace}\: \V{D}\: \V{X}\: \V{Y}\: \V{xs}\: \V{ys}}{}                                     \\
\F{replace}\: (\DHindx{\V{H}}{\V{D}})\: \V{X}\: \V{Y}\: \pair{\V{f}}{\V{xs}}{}\: \pair{\V{g}}{\V{ys}}{} \mapsto   \\
\qquad  \pair{\V{g}}{\F{replace}\: \V{D}\: \V{X}\: \V{Y}\: \V{g}\: \V{ys}}{}
}\]
%
Filling the hole in $\F{cata}$ with \(\F{replace}\: \V{D}\:
(\Mu{\V{D}})\: \V{T}\: \V{xs}\: \V{hs}\) closes the problem. In the
type theory, we have built a generic catamorphism. Any datatype will
now come equipped with this operation, for free.

%% The astute reader will have been struck by the type of $\F{replace}$:
%% it is \emph{almost} the morphism part -- sometimes called \emph{map}
%% -- of the functor $\V{D}$ from $\V{X}$ to $\V{Y}$ in $\Set$. Just as
%% the $\F{induction}$ is the dependent version of $\cata$, $\F{replace}$
%% is the dependent version of the map, which uses the induction
%% hypotheses. For space reason, we will not present the non-dependent
%% map. It can be found in the Agda model.

\begin{wstructure}
<- Deriving generic functions
    <- Taking a Desc and computing a function
        <- Desc comes equipped with an induction principle
        -> Ability to compute more functions from it
            -> More generic functions
    <- Inspecting datatypes
        <- All described byu a Desc code
        -> Ability to explore the code
            <- Desc equipped with an induction principle
            -> Build new objects based on that structure
\end{wstructure}

With this example, we have shown how we can derive a generic
operation, the catamorphism, from a pre-existing generic operation,
the induction principle. This has been made possible by our ability to
manipulate descriptions as first-class objects: the catamorphism is,
basically, a function mapping a $\Desc$ to a datatype specific
operation. This is a form of polytypic programming, as found in
PolyP~\cite{jansson:polyp}.

%% Moreover, the $\F{replace}$ function demonstrates the benefit of an
%% approach based on universes. The datatypes living in the universe of
%% descriptions, we are able to \emph{inspect} them. As shown by
%% $\F{replace}$, it is easy to explore these structures, as well as
%% building new ones.

\subsection{The generic free monad}
\label{sec:desc-free-monad}

\begin{wstructure}
<- A generic program: the free monad construction
    <- Recall free monad construction in Haskell
        -> Based on a functor F
    <- Note that the free monad construction is itself defined by a functor
        -> Extract it
\end{wstructure}

In this section, we will turn to a more ambitious generic operation on
datatype. Given a functor, represented as a tagged description, we
build the free monad over this functor.

\newcommand{\FMFreeMonad}{\D{FreeMonad}}
\newcommand{\FMFreeMonadD}{\D{FreeMonadD}}
\newcommand{\FMVar}{\C{Var}}
\newcommand{\FMComposite}{\C{Composite}}

Let us recall the free monad construction. Given a functor $F$, the
free monad over $F$ is defined by the following datatype:
%
\[
\stk{
\data \FMFreeMonad\: \PITEL{\V{F}}{\Set \To \Set} 
                     \PITEL{\V{X}}{\Set} :
                     \Set 
\where \\
\;\;\begin{array}{@{}l@{\::\:\:}l@{\quad}l}
    \FMVar           & \V{X} \To \FMFreeMonad\: \V{F}\: \V{X}                            \\
    \FMComposite     & \V{F} (\FMFreeMonad\: \V{F}\: \V{X}) \To \FMFreeMonad\: \V{F}\: \V{X}    
\end{array}
}
\]
%
Being an inductive type, this $\FMFreeMonad$ datatype is itself
defined by a pattern functor. It is given by:
%
\[
\FMFreeMonadD\: \V{F}\: \V{X}\: \V{Z} \mapsto \V{X} \mathop{\D{+}} \V{F} \V{Z}
\]

\begin{wstructure}
    <- Encode it in the Desc world [equation]
        <- F is the Desc we start with
        <- The free monad functor is what we have just defined
        <- [\_]* : Desc -> Set -> Desc
           [\_]* D X = 'cons ['var ('sigma X (\_ -> '1))] D
        -> Mu does the fixpoint
\end{wstructure}

In our setting, the free monad construction will take the functor as a
tagged description, a set $\V{X}$ of variables, and will compute the
tagged description of the corresponding free monad. Implementing this
function is surprisingly easy:
%
\[\stk{
\FreeMonad{\_} : \TagDesc \To \Set \To \TagDesc \\
\FreeMonad{\pair{\V{E}}{\V{D}}{}}\:\V{X} \mapsto
    \pair{\ListCons{\DVar{}}{\V{E}}}
         {\pair{\DSigma{\V{X}}{\DUnit}}{\V{D}}{}}{}
}\]
%
We simply add a constructor, $\DVar{\!}$, and define its argument to
be a $\DSigma{\V{X}}{\DUnit}$, that is an element of $\V{X}$. We keep
$\V{E}$ and $\V{D}$ as they were, hence leaving the functor
unchanged. Unfolding the interpretation of this definition, we
convince ourselves that this corresponds to the functor
$\FMFreeMonadD$. The fixpoint operation ties the knot and gives us
the full-blown free monad construction.

\begin{wstructure}
<- A generic program: monadic substitution [equation]
    <- subst : \forall T X Y. mu ([T]* X) -> (X -> mu ([T]* Y)) -> mu ([T]* Y)
        -> Using Fold
\end{wstructure}

Of course, we must equip the resulting datatypes with operations
delivering a monadic interface. As expected, \(\LAM{\x}\DVar{\x}\)
plays the r\^ole of \return, embedding variables into terms. The
\bind\ operation corresponds to \emph{substitution}. We will now
implement it, as a generic function.


\newcommand{\subst}{\F{subst}}
\newcommand{\apply}{\F{apply}}

Our implementation will appeal to the $\cata$ function developed
previously. So, let us write down the types, and fill as much
arguments to $\cata$ as possible:
%
\[\stk{
\begin{array}{@{}ll}
\subst : & \PITEL{\V{D}}{\TagDesc}
           \PI{\V{X}, \V{Y}}{\Set} \\
         & \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{X}}})} \To
           (\V{X} \To \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}) \To
           \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})} 
\end{array} \\
\subst\: \V{D}\: \V{X}\: \V{Y}\: \V{x}\: \V{\sigma} \mapsto
  \cata\: (\toDesc{\FreeMonad{\V{D}}{\V{X}}})\: 
          (\Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})})\: 
          \SHED\: 
          \V{x}
}\]
%
We are left with implementing the algebra of the
catamorphism. Intuitively, its role is to catch appearances of
$\DVar{\V{x}}$ and replace them by $\V{\sigma}\: \V{x}$. This
corresponds to the following definition:
%
\[\stk{
\begin{array}{@{}ll}
\apply : & \PITEL{\V{D}}{\TagDesc} 
           \PI{\V{X}, \V{Y}}{\Set} \\
         & (\V{X} \To \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{X}}})}) \To
           \descop{\toDesc{\FreeMonad{\V{D}}{\V{X}}}}{\Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}} \To
           \Mu{(\toDesc{\FreeMonad{\V{D}}{\V{Y}}})}
\\
\end{array} \\
\begin{array}{@{}l@{\:\mapsto\:\:}l}
\apply\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma}\: \pair{\DVar{\!}}{\V{x}}{}   & \V{\sigma}\: \V{x}                   \\
\apply\: \V{D}\: \V{X}\: \V{Y}\: \V{\sigma}\: \pair{\etag{t}\,}{\V{ys}}{} & \Con{\pair{\etag{t}}{\V{ys}}{}}
\end{array}
}\]

\begin{wstructure}
    -> Consequences
        <- We have free monad datatype
            <- Term + variables
        <- We have monad operations
            <- Return / var
            <- Substitution / bind
\end{wstructure}

Filling the sub-goal with $\apply\: \V{D}\: \V{X}\: \V{Y}\:
\V{\sigma}$ completes the implementation. To sum up, we have
implemented the free monad construction for an arbitrary tagged
description. This gives the developer the ability, for any datatype,
to extend it with a notion of variable. Then, we have equipped this
structure with the corresponding monadic operation, \bind\ and
\return. This construction is an example of type-indexed
datatype~\cite{hinze:generic-haskell}, as found in Generic Haskell:
from a datatype, we built a new datatype and equip it with its
structure.

\begin{wstructure}
<- Deriving new data-structure and functions on them
    <- Computing the Free Monad of a datatype
        <- Derive new data-structure from previous one
            <- It is just code
        /> New data-structure comes with some equipment
    <- Computing new functions on computed datatypes
        <- If data comes with structure, we ought to be able to capture it
            <- Induction on Desc
            -> Ability to compute over data
\end{wstructure}

%% Candidate for removal:
%% With the free monad construction, we have seen two kinds of generic
%% operations. Firstly, we have derived a new data-structure from another
%% one: we make the free monad from its underlying functor. To do so, we
%% crucially rely on the fact that datatypes are nothing but codes. We
%% are therefore entitled to modify this code and, in this case, extend
%% it. Extending a datatype might give rise to a more structured object,
%% as was the case here.  So, secondly, we have equipped this new
%% datatype with its inherent structure: the \bind\ and
%% \return\ operations. We have been able to build them as generic
%% functions.
