\section{Levitating the universe of descriptions}
\label{sec:desc-levitate}

In this section, we will fulfil several promises. One promise we made
was to effectively implement the code of the $\Desc$ universe. Another
promise we tacitly was the existence of the type formers for finite
sets. Despite being a perilous pedagogical exercise for the authors,
we hope to convey to the reader the dizzy feeling of levitation,
without the falling.

\subsection{Implementing finite sets}

\begin{wstructure}
<- Recall typing rules of 1st section
    -> Make clear they were just promises
    -> Can be implemented now
        <- Simply List UId
\end{wstructure}

In Section~\ref{sec:finite-sets}, we have given a specification of
finite sets. It consists in the objects presented in
Figure~\ref{fig:typing-finite-set}. We are going to implement the
$\EnumU$ type former and its constructors. Let us recall their
specification:

\[\stkc{
%% EnumU
\Rule{\Gamma \vdash \Valid}
     {\Gamma \vdash \Type{\EnumU}} 
\\
%% NilE
\Rule{\Gamma \vdash \Valid}
     {\Gamma \vdash \Bhab{\NilE}{\EnumU}} 
\qquad
%% ConsE
\Rule{\Gamma \vdash \Bhab{t}{\UId} \quad
      \Gamma \vdash \Bhab{e}{\EnumU}}
     {\Gamma \vdash \Bhab{\ConsE{t}{e}}{\EnumU}}
}\]

The names $\NilE$ and $\ConsE{}{}$ are absolutely not a
coincidence. $\EnumU$ is indeed isomorphic to a list of $\UId$s. In
Section~\ref{sec:desc-examples}, we have shown how to build lists in
the universe of description. Therefore, the actual implementation of
$\EnumU$ boils down to the following, trivial definition:

\[\stk{
\EnumU : \Set \\
\EnumU \mapsto \Mu{(\ListD~\UId)}
}\]


\begin{wstructure}
<- Consequences
    -> Type theory doesn't need to be extended with EnumU, NilE, and ConsE
        <- EnumU == Mu EnumUD
        <- NilE, ConsE are just tags
    -> Do not need a specific \spi eliminator
        <- \spi is an instance of the generic eliminator
            <- Code?
    -> Anything else remains the same (switch, EnumT, 0, 1+)
\end{wstructure}

Let us examine the consequences of our act. First of all, we discover
that the type theory does not actually need to be extended with the
type former $\EnumU$, the constructors $\NilE$ and $\ConsE$. We have
just defined $\EnumU$ above, by fix-point over the signature functor
$\ListD$. $\NilE$ and $\ConsE$ are simply the $\ListNil$ and
$\ListCons$ constructors of lists.

Another interesting consequence concerns the $\spi{}{}$ operator: it
can actually be implemented with the generic $\F{induction}$
principle. From an implementation perspective, this means that we
remove an operator hard-coded in the host language. This operator is
simply implemented in the dependently-typed target language, as any
other function.

Apart from these changes, we are left with implementing the other
components of finite sets. This consists in $\EnumT$, $\Ze$, $\Su$, as
well as the $\F{switch}$ operator. Note that the actual implementation
of $\EnumU$ does not influence our implementation of $\EnumT$: be they
hard-coded or codes in the $\Desc$ universe, the $\EnumU$ objects just
behave similarly. We have witnessed this effect when carrying this
operation in Epigram, moving from an hard-coded presentation to a
self-hosted one. Absolutely no change to the $\EnumT$ objects was
required.

\begin{wstructure}
<- Summary of the operation
    <- The content of the type theory is exactly the same
        <- before == after
    /> type naming scheme condenses
        <- Replace named constructors by codes in the universe of data-types
    -> Our next step is a similar move (in essence)
        /> Condenses the entire naming scheme of data-types
\end{wstructure}

In this section, we have replaced a low-level presentation of finite
sets by a self-hosted one, expressed in the universe of
descriptions. However, formally, the content of the type theory
remains unchanged: objects which were present before the modification
are still there. Conversely, we have not introduced any spurious
object.

If not on the content, this modification had an effect on the
names. The type naming scheme of the type theory has condensed: named
type formers ($\EnumU$) and constructors ($\NilE$ and $\ConsE$) are
now replaced by codes and their fix-point in the universe of
descriptions. In essence, our next step is similar: we are going to
condense the entire naming scheme of data-types \emph{in itself}.

\subsection{Implementing descriptions}

\begin{wstructure}
<- Realising our promises
    <- We are going to implement Desc
    /> Desc is itself a data-type
        <- Same situation as EnumU
            <- We want to benefit from generic operations
        -> It ought to be encoded in itself
\end{wstructure}

We shall now fulfil our promises for $\Desc$. We are going to
implement the codes of the universe of descriptions. Interestingly, in
and by itself, a code is nothing but a data-type. We are in the same
situation than with $\EnumU$: we ought to be able to describe the
codes of $\Desc$ in $\Desc$ itself. Hence, this code would be a
first-class citizen, born with the standard, generic equipment of
data-types.

\subsubsection{First attempt}

\begin{wstructure}
<- A partial implementation
    <- '1 and 'indx are easy
    <- 'sigma is partially doable
        /> lack the ability to do an higher-order inductive call
    -> Show partial code [figure]
\end{wstructure}

Our first tentative is the following:

\[\stk{
\DescD : \Desc \\
\begin{array}{@{}ll}
\DescD \mapsto \DSigma{}{} & (\EnumT [ \DUnit, \DSigma{}{}, \DIndx{} ])  \\
                           & \left[\begin{array}{l}
                                   \DUnit                                \\
                                   \DSigma{\Set}{(\LAM{\V{S}} ???)}      \\
                                   \DIndx{\DUnit}                        \\
                                   \end{array}
                             \right]
\end{array}
}\]

Let us explain how we have proceeded and the obstacle we face. Much as
the data-types we have seen so far, we first have to choose a
constructor. Constructors correspond to the code's constructors:
$\DUnit$, $\DSigma$, and $\DIndx$. The reader will notice that the
tagged notation we have used so far for $\Desc$ constructors now fully
make sense: these were actually the tags we are defining. \note{This
  sentence badly needs a rephrasing.}

The case of $\DUnit$ is trivial: we immediately reach the end of the
data-type. $\DUnit$ has no payload. The case of $\DIndx{}$ comes
naturally: it only takes a recursive argument -- a description. The
case of $\DSigma$ is problematic. Recall the specification of
$\DSigma$:

\[    \DSigma{}{} : \PI{\V{S}}{\Set} \PIS{S \To \Desc} \Desc      \]

So, we first pack an element $S$ of $\Set$. Then, we would like to
express a notion of recursive argument \emph{indexed} by $S$. Because
our presentation is entirely first-order so far, we are not able to
express this notion. We shall remedy to this situation.


\subsubsection{Second attempt}

\begin{wstructure}
<- Extending the universe of description
    -> With higher-order induction
    <- Intuition: index elements in X by H, and go on reading
        -> indx is isomorph to hindx for H = 1
    /> Keep indx
        <- First order!
        -> Extensionally equal to hindx 1
        /> Practically, definitional equality on Sigma/Pi cannot cope with it
    -> Show DescD code
\end{wstructure}

In order to capture a notion of higher-order induction, we need to
extend our universe of descriptions. This consists in adding a code
$\DHindx$ that takes an indexing set $H$. The code and its
interpretation are presented in
Figure~\ref{fig:hindx_desc}. Intuitively, $\DHindx$ use the elements
of $H$ to index as many recursive arguments. 

\begin{figure*}

\[
\begin{array}{ll}
\stk{
\data \Desc : \Set \where \\
\;\;\begin{array}{@{}l@{\::\:\:}l@{\quad}l}
    \ldots          & \:\:\ldots \\
    \DHindx         & \PI{H}{Set} \Desc \To \Desc
\end{array}
}
&
\stk{
\descop{\_\:}{} : \Desc \To \Set \To \Set \\
\begin{array}{@{}l@{\:=\:\:}ll}
\ldots                        &  \ldots \\
\descop{\DHindx{H}{D}}{X}     &  \TIMES{(H \To X)}{\descop{D}{X}}
\end{array}
}
\end{array}
\]

\caption{Higher-order universe of descriptions}
\label{fig:hindx_desc}

\end{figure*}


Note that $\DIndx$ is isomorphic to $\DHindx{\Unit}$. However, we
tolerate this duplication and do not replace $\DIndx$ by the more
general $\DHindx$. Indeed, unlike its counterpart, $\DIndx$ is
first-order. Therefore, while both codes are \emph{extensionally} the
same, in most practical implementation they would be dealt with rather
differently. While definitional equality can cope with first order
objects, the functional presentation introduced by $\DHindx$ is
unlikely to be amenable to a purely definitional treatment.

Equipped with $\DHindx$, we can describe the extended code of our
universe of data-types, as shown in Figure~\ref{fig:desc-levitate}.
The $\DUnit$ and $\DIndx$ cases remains unchanged, as expected. We
successfully describe the $\DSigma$ case, by a simple appeal to the
higher-order induction on $S$. The $\DHindx$ case consists in packing
the $H$ in $\Set$ with a recursive argument.

In a first glance, we have achieved our goal. We have described the
codes of the universe of description. Taking the fix-point of this
object gives us $\Desc$, up to isomorphism. We have implemented our
code of data-types as an object levitating inside itself. However,
this levitation operation, just as any magic trick, relies on an
invisible cable. Let us reveal it, hence finishing our implementation.

\begin{figure}

\[\stk{
\DescD : \Desc \\
\begin{array}{@{}ll}
\DescD \mapsto \DSigma{}{} & (\EnumT [ \DUnit, \DSigma{}{}, \DIndx{}, \DHindx{}{} ]) \\
                           & \left[\begin{array}{l}
                                   \DUnit                                            \\
                                   \DSigma{\Set}{(\LAM{\V{S}} \DHindx{S}{\DUnit})}   \\
                                   \DIndx{\DUnit}                                    \\
                                   \DSigma{\Set}{(\LAM{\V{H}} \DIndx{\DUnit})}
                                   \end{array}
                             \right]
\end{array}
}\]

\caption{Levitating description of $\Desc$}
\label{fig:desc-levitate}

\end{figure}

\subsubsection{Final move}

\begin{wstructure}
<- Subtlety: translation of [ ... ]
    -> Let us do it manually
        -> Code with problem for the motive of switch
\end{wstructure}

Our reader might be slightly confused to learn that the trick is
visible in the definition of $\DescD$
(Fig.~\ref{fig:desc-levitate}). Or rather, it is made invisible by
careful usage of type propagation. Indeed, let us try to elaborate
this term down to the low-level type theory. The $\EnumT [ \ldots ]$
construct elaborates to a finite set $e$ in $\EnumU$, inhabited by the
codes. Then, we can type-check the case definition, between square
brackets $[ \ldots ]$. This term $f$ is pushed into the type
$\EnumT{e} \To \Desc$. This corresponds to a finite function
definition, as formalised in Figure~\ref{fig:type-checking}.

What happens if we unfold the definition? We ought to build the following term:

\[
\PLAM{x}{(\EnumT{e})} \switch{e}{(\LAM{\_} \Mu{\DescD})}{\pi^f}{x}
\]

But this is quite problematic. We are still in the process of
constructing $\DescD$, and the motive of $\F{switch}$ is abruptly
begging for this very same $\DescD$. Despite our willingness, we
cannot materialise such motive.

\begin{wstructure}
<- The magician trick
    <- Our problem is to give a motive for switch
        /> We perfectly know what it ought to be: \_ -> DescD
    -> Solution: extend the type theory with a special purpose switchD
        -> Only extension required to the type theory!
        -> Hidden away to the user by the syntactic sugar
            -> Sufficient to ensure unavailability as a raw operator
            <- Another instance of type propagation
\end{wstructure}

If we cannot make it happen, we simply do not make it happen. We
perfectly know what the motive ought to be. Consequently, we extend
the type theory with a special-purpose operator:

\[
\begin{array}{@{}ll}
%% switchD
\F{switchD} : & \PITEL{\V{e}}{\EnumU}               
                \PITEL{\V{b}}{\spi{e}{\LAM{\_} \Desc}}
                \PITEL{\V{x}}{\EnumT{e}} \To \Desc
\end{array}
\]

The entire work of the magician stands here, in this extension. One
could be worried by the availability of such operations in our type
theory. Indeed, it would be inconvenient for the user to have to
decide between two variants. The solution to this problem is, once
again, to use the type propagation system. Just as the $\F{switch}$
operator, $\F{switchD}$ can be automatically elaborated. To this end,
we extend the type-checking rules (Fig.~\ref{fig:type-checking}) with
the following inference rule:

\[
\Rule{\Gamma \Vdash \propag{\push{t}{\spiD{e}}}
                           {t'}}
     {\Gamma \Vdash \begin{array}{@{}l}
                        \propag{\push{t}{\EnumT{e} \To \Desc}}
                               {\\ \PLAM{x}{(\EnumT{e})} \switchD{e}{t'}{x}}
                    \end{array}
     }\;\mbox{t is $[]$ or $[a,b]$}
\]


\begin{wstructure}
<- Generic programming now!
    <- Desc is just data
        -> Can be manipulated
    <- Free induction scheme on Desc
        -> Ability to inspect data-types
        -> Ability to program on data-types
\end{wstructure}


\note{
Maybe a bit of perspective would be good: 
Everything stands up with the Mu.
Induction principle defined over Mu-things.
}

This concludes our levitation work. Beyond its pedagogical value, this
exercise has several practical outcomes. First of all, this exercise
reveals that the $\Desc$ universe is just plain data. Just as any
piece of data, it can therefore be inspected and
manipulated. Moreover, it is expressed in the $\Desc$ universe. As a
consequence, it is equipped, for free, with an induction
principle. So, our ability to inspect and program with $\Desc$ is not
restricted to the meta-language: we now have all the necessary
equipment in the target language to \emph{program} over data-types. In
this setting, \emph{generic programming is just about programming}.


\subsection{The generic catamorphism}

\begin{wstructure}
<- Making cata
    <- Present the type signature
    <- Starts with a call to generic induction
        <- induction on Desc!
        /> Show types at hand
        -> Explain how to use inductive hypothesis
    <- Implement the 'replace' function
    -> Dependent-typeless catamorphism 
\end{wstructure}

In Section~\ref{sec:desc-fix-point}, we have argued for the
implementation of a dependently-typed $\F{induction}$ principle,
instead of the more traditional catamorphism. However, in some
circumstances, the full-power of a dependent elimination is not
necessary. In the following, we propose to derive the catamorphism
from the generic induction principle. 

The catamorphism can be characterised as an induction on the
description $D$, with a non-dependent motive targeting $T$. Given a
node $xs$ and the induction hypotheses, the method ought to build an
element of $T$. Provided that we know how to make an element of
$\descop{D}{T}$, this step will be performed by the algebra $f$. Let
us take a look at this jigsaw:

\newcommand{\cata}{\F{cata}}

\[\stk{
\cata : \PITEL{D}{\Desc}
           \PI{T}{\Set}
           (\descop{D}{T} \To T) \To 
           \Mu{D} \To T \\
\cata\: D\: T\: f \mapsto
  \F{induction}\: D\: (\LAM{\_}T)\: (\LAM{xs\:hs} f\: ???)
}\]

We are left with implementing the \(???\) program. Recall that we have
\(\Bhab{xs}{\descop{D}{\Mu{D}}}\) and
\(\Bhab{hs}{\All{D}{(\Mu{D})}{(\LAM{\_} T)}{xs}}\) at hand. Our goal
is to make an element of \(\descop{D}{T}\). Intuitively, $xs$ is of
the right shape, but its sub-elements are of the wrong type. On the
other hand, for each sub-element of $xs$, $hs$ gives us the
corresponding element in $T$. Hence the name ``induction
hypotheses''. Therefore, to construct an element of \(\descop{D}{T}\),
we replace the recursive components of \(xs\) by their counterpart in
\(hs\):

\[\stk{
\F{replace} : \stk{\PITEL{D}{\Desc}
                   \PITEL{X,Y}{\Set}\\
                   \PI{xs}{\descop{D}{X}} 
                   \All{D}{X}{(\LAM{\_}Y)}{xs} \To
                   \descop{D}{Y}} \\
\F{replace}\: \DUnit\:          X\: Y\: \Void\:          \Void          \mapsto \Void \\
\F{replace}\: (\DSigma{S}{D})\: X\: Y\: \pair{s}{xs}{}\: ys             \mapsto
    \pair{s}{\F{replace}\: {D~s}\: X\: Y\: xs\: ys}{}                                 \\
\F{replace}\: (\DIndx{D})\:     X\: Y\: \pair{x}{xs}{}\: \pair{y}{ys}{} \mapsto
    \pair{y}{\F{replace}\: D\: X\: Y\: xs\: ys}{}
}\]

Filling the \(???\) with \(\F{replace}\: D\: (\Mu{D})\: T\: xs\: hs\) closes the
problem. In the type theory, we have built a generic catamorphism. Any
data-type will now come equipped with this operation, for free.

\begin{wstructure}
<- Deriving generic functions
    <- Taking a Desc and computing a function
        <- Desc comes equipped with an induction principle
        -> Ability to compute more functions from it
            -> More generic functions
    <- Inspecting data-types
        <- All described byu a Desc code
        -> Ability to explore the code
            <- Desc equipped with an induction principle
            -> Build new objects based on that structure
\end{wstructure}

With this example, we have shown how we can derive a generic
operation, the catamorphism, from a pre-existing generic operation,
the induction principle. This has been made possible by our ability to
manipulate descriptions as first-class objects: the catamorphism is,
basically, a function mapping a $\Desc$ to a data-type specific
operation.

Moreover, the $\F{replace}$ function demonstrates the benefit of an
approach based on universes. The data-types living in the universe of
descriptions, we are able to \emph{inspect} them. As shown by
$\F{replace}$, it is easy to explore these structures, as well as
building new ones.

\subsection{The generic Free Monad}
\label{sec:desc-free-monad}

\begin{wstructure}
<- A generic program: the free monad construction
    <- Recall free monad construction in Haskell
        -> Based on a functor F
    <- Note that the free monad construction is itself defined by a functor
        -> Extract it
\end{wstructure}

In this section, we will turn to a more ambitious generic operation on
data-type. Given a functor, represented as a tagged description, we
build the free monad over this functor.

\newcommand{\FMFreeMonad}{\D{FreeMonad}}
\newcommand{\FMFreeMonadD}{\D{FreeMonadD}}
\newcommand{\FMVar}{\C{Var}}
\newcommand{\FMComposite}{\C{Composite}}

Let us recall the free monad construction. Given a functor $F$, the
free monad over $F$ is defined by the following data-type:

\[
\stk{
\data \FMFreeMonad : \PITEL{\V{F}}{\Set \To \Set} 
                     \PI{\V{X}}{\Set} 
                     \Set 
\where \\
\;\;\begin{array}{@{}l@{\::\:}l@{\quad}l}
    \FMVar           & X \To \FMFreeMonad\: F\: X                            \\
    \FMComposite     & F (\FMFreeMonad\: F\: X) \To \FMFreeMonad\: F\: X    
\end{array}
}
\]

\note{Recall monadic structure of this object}

Being an inductive type, this $\FMFreeMonad$ data-type is itself
defined by a functor signature. It is given by:

\[
\FMFreeMonadD\: F\: X\: Z \mapsto X + F Z
\]

\begin{wstructure}
    <- Encode it in the Desc world [equation]
        <- F is the Desc we start with
        <- The free monad functor is what we have just defined
        <- [\_]* : Desc -> Set -> Desc
           [\_]* D X = 'cons ['var ('sigma X (\_ -> '1))] D
        -> Mu does the fix-point
\end{wstructure}

In our setting, the functor will be represented by a tagged
description. The free monad construction will take such tagged
description, a set $X$ of variables, and will compute the tagged
description of the corresponding free monad. Implementing this
function is surprisingly easy:

\[\stk{
\FreeMonad{\_} : \TagDesc \To \Set \To \TagDesc \\
\FreeMonad{\pair{E}{D}{}}\:X \mapsto
    \pair{\ListCons{\DVar{}}{E}}
         {\pair{\DSigma{X}{\DUnit}}{D}{}}{}
}\]

We simply add a constructor, $\DVar{}$, and define its argument to be
a $\DSigma{X}{\DUnit}$, that is an element of $X$. We keep $E$ and $D$
as they were, hence leaving the functor unchanged. Unfolding the
interpretation of this definition, we convince ourself that this
corresponds to the functor $\FMFreeMonadD$. The fix-point operation
ties the knot and gives us the full-blown free monad construction.

\begin{wstructure}
<- A generic program: monadic substitution [equation]
    <- subst : \forall T X Y. mu ([T]* X) -> (X -> mu ([T]* Y)) -> mu ([T]* Y)
        -> Using Fold
\end{wstructure}

Of course, we must equip the resulting data-types with operations
delivering a monadic interface. As usual, \(\LAM{\x}\DVar{\x}\)
performs the r\^ole of \return, embedding variables into terms. The
\bind operation corresponds to \emph{substitution}. We will now
implement it, as a generic function.

Our implementation will appeal to the $\cata$ function developed
previously. So, let us write down the types, and fill as much
arguments to $\cata$ as possible:

\newcommand{\subst}{\F{subst}}
\newcommand{\apply}{\F{apply}}

\note{This is not quite Mu of a tagged description}

\[\stk{
\begin{array}{@{}ll}
\subst : & \PITEL{\V{D}}{\TagDesc}
           \PI{\V{X}, \V{Y}}{\Set} \\
         & \Mu{(\toDesc{\FreeMonad{D}{X}})} \To
           (\V{X} \To \Mu{(\toDesc{\FreeMonad{D}{Y}})}) \To
           \Mu{(\toDesc{\FreeMonad{D}{Y}})} 
\end{array} \\
\subst\: D\: X\: Y\: x\: \sigma \mapsto
  \cata\: (\toDesc{\FreeMonad{D}{X}})\: 
          (\Mu{(\toDesc{\FreeMonad{D}{Y}})})\: 
          ???\: 
          x
}\]

Our task is therefore to implement the algebra of the
catamorphism. Intuitively, its role is to catch appearances of
$\DVar{x}$ and replace them by $\sigma x$. Otherwise, it should simply
appeal to the induction hypothesis. This corresponds to the following
definition:

\[\stk{
\begin{array}{@{}ll}
\apply : & \PITEL{\V{D}}{\TagDesc} 
           \PI{\V{X}, \V{Y}}{\Set} \\
         & (\V{X} \To \Mu{(\toDesc{\FreeMonad{D}{X}})}) \To
           \descop{\toDesc{\FreeMonad{D}{X}}}{\Mu{(\toDesc{\FreeMonad{D}{Y}})}} \To
           \Mu{(\toDesc{\FreeMonad{D}{Y}})}
\\
\end{array} \\
\begin{array}{@{}l@{\:\:\mapsto\:}l}
\apply\: D\: X\: Y\: \sigma\: \pair{\DVar{}}{x}{}   & \sigma\: x                   \\
\apply\: D\: X\: Y\: \sigma\: \pair{\etag{t}}{ys}{} & \Con{\pair{\etag{t}}{ys}{}}
\end{array}
}\]

\begin{wstructure}
    -> Consequences
        <- We have free monad data-type
            <- Term + variables
        <- We have monad operations
            <- Return / var
            <- Substitution / bind
\end{wstructure}

Filling the $???$ sub-goal with $\apply\: D\: X\: Y\: \sigma$
completes the implementation. To sum up, we have implemented the free
monad construction for an arbitrary tagged description. This gives our
user the ability, for any data-type, to extend it with a notion of
variable. Then, we have equipped this structure with the corresponding
monadic operation, \bind and \return. Whereas the \return is a trivial
variable former, the \bind operation corresponds to the substitution
of variables by terms. We have shown how to implement it, for any free
monad.


\begin{wstructure}
<- Deriving new data-structure and functions on them
    <- Computing the Free Monad of a data-type
        <- Derive new data-structure from previous one
            <- It is just code
        /> New data-structure comes with some equipment
    <- Computing new functions on computed data-types
        <- If data comes with structure, we ought to be able to capture it
            <- Induction on Desc
            -> Ability to compute over data
\end{wstructure}

With the free monad construction, we have seen two kind of generic
operations. Firstly, we have derived a new data-structure from another
one: we make the free monad from its underlying functor. To do so, we
crucially rely on the fact that data-types are nothing but codes. We
are therefore entitled to modify this code and, in this case, extend
it. Extending a data-type might give rise to a more structured
object, as was the case here.

So, secondly, we have equipped this new data-type with its inherent
structure: the \bind and \return operations. We have been able to
build them as generic functions. Here, we rely on our ability to
compute over descriptions, thanks to the induction principle.
