\section{A universe of inductive datatypes}
\label{sec:universe-desc}

\begin{wstructure}
<- Why starting with simple datatypes
    <- For pedagogical purposes
        <- datatypes as we know them every day
        /> Target dependent types
    -> Cut down version of Induction Recursion
        -> Presentation evolves independently as we go to dependent types
\end{wstructure}

In this section, we describe an implementation of inductive types, as
we know them in ML-like languages. This choice is motivated by
pedagogical considerations: by describing the layman datatypes in our
setting, we build on our intuition of datatypes we are familiar
with. In particular, we do not aim at describing a model for generics
in simply-typed functional language. Our goal is and remains to
discuss datatypes as we find them in dependently-typed languages.

Our proposal is inspired by, but less involved than, Dybjer and
Setzer's closed formulation of
induction-recursion~\cite{dybjer:general-ir, dybjer:axiom-ir,
  dybjer:ir-initial-algebra, dybjer:iir}. For inductive datatypes, the
full power of induction-recursion is not necessary. Therefore, we
adopt a stripped-down version of it. As we broaden the scope of our
universe of datatypes, our presentation will diverge from
induction-recursion. We shall compare both approaches in
Section~\ref{sec:discussion}.

\subsection{The power of $\Sigma$}

\begin{wstructure}
<- The duality of Sigma
    <- Sigma generalises sum over arbitrary arities
        -> \Sigma A B == \Sigma_{x : A} B x
    <- Sigma generalises product to have a dependant second component
        -> \Sigma A B == (x : A) \times (B x)
\end{wstructure}

In dependently-typed languages, $\Sigma$-types can be interpreted in
two different ways. This duality is actually reflected in the notation
we can find in the literature, depending on the sensibility of the
author.  The notation $\blue{\Sigma}_{\V{x} : \V{A}} (\V{B}\: \V{x})$
stresses the interpretation that $\Sigma$-types are a generalisation
of sums over arbitrary arities.  Where simply-typed languages have
finite sums, dependently-typed languages have sums indexed by any set.

On the other hand, our choice of notation $\SIGMA{\V{x}}{\V{A}} (\V{B}\:\V{x})$
emphasises that $\Sigma$-types can be read as a generalisation of products,
where the second component can depend on the first one. When simply-typed
languages pack data into non-dependent tuples, dependently-typed languages
tolerate this non-dependent usage. However, they also give the rather novel
ability for data to influence types of further data.

\begin{wstructure}
<- datatypes in the simply-typed world
    -> "sums-of-product"
        <- Sum of constructors
        <- Product of arguments
<- datatypes in the dependently-typed world
    -> "sigmas-of-sigmas"
    /> Need ability to manipulate these sigmas
        -> Define a Code for datatypes
        -> Together with a sigma-based Interpretation
\end{wstructure}

In the simply-typed world, datatype definitions are often referred to
as \emph{sum-of-product}. A datatype is defined by a finite sum -- a
choice -- of constructors, each of them is composed of a product -- a
tuple -- of arguments. This form governs the grammar of datatype
definition in languages such as Haskell or ML.

To model these datatypes, we simply need to capture this grammar in
our dependently-typed setting. Here, the notion of sum-of-product
naturally translates into \emph{sigmas-of-sigmas}. Beyond this
intuition, it should be clear that a direct encoding of datatypes
through raw $\Sigma$-types is not a viable option. Indeed, just as for
finite sets, encoding throws away information when we crucially need
it. Moreover, to program with these datatypes, one would need an
induction principle. An encoding will be unable to deliver such
operation~\cite{geuvers:induction-not-derivable}.


\subsection{A universe of descriptions}
\label{sec:desc-universe}

\begin{wstructure}
<- Introduction to Universe construction
    <- Define a Code
        -> Name objects
    <- Define an Interpretation of codes into the type theory
        -> Give a semantics to objects
    -> Ability to manipulate code
    -> Ability to compute with these objects
\end{wstructure}

While sigmas-of-sigmas form a convenient \emph{semantics} for
datatypes, we have seen that it makes a poor \emph{syntax}. To
decouple these two notions, we use a standard technique in
dependently-typed programming: we construct an ad-hoc universe. This
technique dates back to Martin-L\"of definition of type
theory~\cite{martin-lof:itt}. Since then, it has been fruitful as a
programming technique~\cite{benke:universe-generic-prog,
  oury:power-of-pi} \note{Any idea of other papers?}.  We refer the
reader to the Agda tutorial~\cite{norell:agda-tutorial} for a
pedagogical presentation of universe construction.  \note{Is that
  really a motivating motivation for the usage of universe
  construction?}  \note{pwm: Surely ($\EnumU$, $\EnumT$) is a useful
  example of universes too.  Even if it doesn't show off their full
  power?}


The key idea behind universe construction is our ability to make names
by defining new types. These names are called \emph{codes}. By
defining a set of codes, we define the syntax of a language. However,
as such, a system of codes is useless as it lacks a semantics. Instead
of equipping the universe of codes with some computational behaviour,
we pragmatically chose to \emph{interpret} these codes back into the
standard type theory. Hence, codes act only as labels, while the type
theory provides the computational machinery. \note{Is that a good
  description?}

Codes being simple labels, we have the ability to inspect them, hence
regaining structural information. Being able to inspect them, we are
therefore free to compute over them: deriving new codes from previous
ones, or even new functions on them. In several occasions, we will
have the opportunity to witness the power of universes.

\begin{wstructure}
<- Justification of the code 
    <- [both figures]: cannot be read separately
    <- Mimic the standard grammar of datatypes description
        -> Just as we already know it
        <- '\Sigma for making sigmas-of-sigmas
        <- 'indx for exhibiting the functoriality
            -> For recursive arguments
        <- '1 for end of description
\end{wstructure}

We propose to embed inductive types as a universe in our dependent
type theory, the universe of \emph{descriptions}
(Figure~\ref{fig:desc_universe}). As expected, the code of this
universe mimics the standard grammar of datatypes definitions in
simply-typed languages. Hence, we have a $\DSigma{\!}{\!}$ code,
interpreted as a $\Sigma$-type, to build the
sigmas-of-sigmas. Descriptions are terminated by $\DUnit$, which
contains no useful payload. The functoriality of the datatypes is
introduced by $\DIndx{\!}$. When we tie the knot with a fix-point, the
hole left open by $\DIndx{\!}$ will be turned into a standard
recursive argument. We notice that this functoriality appears in the
type of $\descop{\V{D}}{\!}$ itself, for a given datatype definition
$\V{D}$. This corresponds to the object part of the functor described
by $\V{D}$.

\begin{figure}

\[\stk{
\begin{array}{ll}
\stk{
\data \Desc : \Set \where \\
\;\;\begin{array}{@{}l@{\::\:\:}l@{\quad}l}
    \DUnit          & \Desc \\
    \DSigma{\!}{\!} & \PI{\V{S}}{\Set} \PIS{\V{S} \To \Desc} \Desc \\
    \DIndx{\!}      & \Desc \To \Desc
\end{array}
}
\vspace{0.2in}
\\
\stk{
\descop{\_\:}{} : \Desc \To \Set \To \Set \\
\begin{array}{@{}ll@{\:=\:\:}ll}
\descop{\DUnit}{& \V{X}}        &  \Unit                                       \\
\descop{\DSigma{\V{S}}{\V{D}}}{& \V{X}} &  \SIGMAS{\V{s} : \V{S}}{\descop{\V{D}~\V{s}}{\V{X}}}         \\
\descop{\DIndx{\V{D}}}{& \V{X}}     &  \TIMES{\V{X}}{\descop{\V{D}}{\V{X}}}
\end{array}
}
\end{array}
}\]


\caption{Universe of Descriptions}
\label{fig:desc_universe}

\end{figure}

To give some intuition on this universe of descriptions, we now turn
to some examples. For obvious pedagogical reasons, we will manually
build these descriptions. However, it should be clear that, in
practice, these definitions can be automatically constructed from an
ML-like $\data$ definition.

\subsection{Examples}
\label{sec:desc-examples}

\begin{wstructure}
<- Nat
    <- Sum of zero, suc
    <- zero case: done
    <- suc case: leave open and done
    -> NatD Z = 1 + Z
\end{wstructure}

Our first example is the natural numbers, or rather its pattern
functor. Our code is presented in the high-level expression language
of Section~\ref{sec:type-propagation}. The translation back to the raw
terms is laborious but should not pose any difficulty. The code is the
following:

\[\stk{
\NatD : \Desc \\
\NatD \mapsto \DSigma{(\EnumT{[ \NatZero, \NatSuc{\!} ]})}
                     {[ \DUnit \quad (\DIndx{\DUnit}) ]}
}\]

Let us explain its construction. First, we use $\DSigma{\!}{\!}$ to
give a choice between the $\NatZero$ and $\NatSuc{\!}$
constructors. In the $\NatZero$ case, we reach the end of the
description: there is no useful payload in that case. In the
$\NatSuc{\!}$ case, we leave one hole open for the recursive argument,
and we close the description.

In a more synthetic notation, we have described the following functor:

\[    \NatD\: \V{Z} \mapsto \Unit \mathop{\D{+}} \V{Z}    \]

\begin{wstructure}
<- List
    <- Sum of nil, cons
    <- nil case: done
    <- cons case: product of X with leave open and done
    -> ListD X Z = 1 + X * Z
\end{wstructure}

With a small change to the definition of $\NatD$, we obtain the
pattern functor for lists:

\[\stk{
\ListD : \Set \To \Desc \\
\ListD \: \V{X} \mapsto \DSigma{(\EnumT{[ \ListNil, \ListCons{\!}{\!} ]})}
                           {[ \DUnit \quad (\DSigma{\V{X}}{\LAM{\_} \DIndx{\DUnit}}) ]}
}\]


The modification consists in turning the $\NatSuc{\!}$ constructor
into a proper $\ListCons{\!}{\!}$ taking an argument in $\V{X}$
followed by a recursive argument. In this case, we use
$\DSigma{\!}{\!}$ in its product interpretation: we pack an element of
$\V{X}$ together with the recursive argument. Easily, one sees that
this code actually describes the following functor:

\[    \ListD\: \V{X}\: \V{Z} \mapsto \Unit \mathop{\D{+}} \V{X} \D{\ensuremath{\times}} \V{Z}     \]

\begin{wstructure}
<- Tree
    <- sum of leaf, node
    <- leaf case: done
    <- node case: product of X with two leave open and done
    -> TreeD X Z = 1 + X * Z * Z
\end{wstructure}

Finally, we are not limited to one recursive argument. This is
demonstrated by our description of binary trees:

\[\stk{
\TreeD : \Set \To \Desc \\
\begin{array}{@{}ll}
\TreeD \: \V{X} \mapsto \DSigma{ & (\EnumT{[ \TreeLeaf, \TreeNode ]}) \\}
                           { & [ \DUnit \quad (\DSigma{\V{X}}{\LAM{\_} \DIndx{(\DIndx{\DUnit})}}) ]}
\end{array}
}\]

Again, we are at one evolutionary step away from $\ListD$. However,
instead of a single call to the induction code, we call it twice. The
interpretation of this code corresponds to the following functor:

\[    \TreeD\: \V{X}\: \V{Z} \mapsto \Unit \mathop{\D{+}} \V{X} \Prod \V{Z} \Prod \V{Z}     \]


\begin{wstructure}
<- Tagged description
    <- Form TDesc = List (UId x Desc) [equation]
    <- Follow usual sums-of-product presentation of datatype
        <- Finite set of constructors
        <- Then whatever you want
    -> Any Desc datatype can be turned into this form
        -> No loss of expressive power
        /> Guarantee a ``constructor form''
\end{wstructure}

From the examples above, we observe that datatypes are defined by a
$\DSigma{\!}{\!}$ which first argument is a finite set of
constructors. The descriptions fitting into this pattern are called
\emph{tagged} description. Formally, we have:

\[
 \TagDesc \mapsto \SIGMA{\V{E}}{\EnumU} (\spi{\V{E}}{(\LAM{\_} \Desc)})
\]

Again, this is a clear reminiscence of the sum-of-product style:
we have a finite sum of constructors. Of course, every description can
be expressed in this style, using a singleton as single constructor if
necessary. A tagged description can trivially be turned into a
full-blown description. We write $\toDesc{\V{TD}}$ for the description computed
from the tagged description $\V{TD}$.

\begin{wstructure}
<- Fictive object [figure 'data Desc']
    -> Must be read as a type signature
    -> See further for its actual implementation
        <- Subject to our levitation exercise
\end{wstructure}

For convenience, we have taken for granted the existence of $\Desc$,
as presented in Figure~\ref{fig:desc_universe}. In particular, we have
considered its codes, $\DSigma{\!}{\!}$, $\DIndx{\!}$, and $\DUnit$ as
type formers, extending the basic type theory. Hence, in an
implementation of this type theory, we need to extended it with these
constructors and their typing rules. Although it makes no conceptual
difference, the code of description should rather be read as a
specification. We promise the existence of such objects, satisfying
the typing rules. It will be the subject of
Section~\ref{sec:desc-levitate} to fulfil this promise, by actually
implementing the specification.

\subsection{Fix-point}
\label{sec:desc-fix-point}

\begin{wstructure}
<- Build the fix-point of functors
    <- See examples: need to build their initial algebra
    -> Extend the type theory with Mu/Con [figure]
        <- Straightforward definition of a fix-point
            <- Interpret D with (Mu D) as sub-objects
\end{wstructure}


So far, we have used our universe of descriptions to build
functors. \note{ Strictly positive types anyone? } To illustrate its
usage, we have implemented the pattern functors of natural numbers,
lists, and binary trees. However, the class of functors expressible
with descriptions enjoys another property: they all admit a
fix-point. Indeed, descriptions are interpreted into \emph{polynomial
  functors}~\cite{who?}\note{who is the relevant source for polynomial
  functors?}, as they are only composed of $\Sigma$-types, the unit
type, and variables.

We construct the fix-point by \emph{tying the knot} of the
interpretation: the holes left open by the functor are filled by its
own recursive definition:

\[
\Rule{\Gamma \vdash \Bhab{\V{D}}{\Desc}}
     {\Gamma \vdash \Bhab{\Mu{\V{D}}}{\Set}} \qquad
\Rule{\Gamma \vdash \Bhab{\V{D}}{\Desc} \quad 
      \Gamma \vdash \Bhab{\V{x}}{\descop{\V{D}}{(\Mu{\V{D}})}}}
     {\Gamma \vdash \Bhab{\Con{\V{x}}}{\Mu{\V{D}}}}
\]

\begin{wstructure}
<- Elimination on Mu
    <- We are used to foldD : \forall X. (desc D X -> X) -> mu D -> X
        /> Not dependent
        -> Cannot express some (which one again?) properties
    -> Develop a dependent induction
        <- Everywhere/All
        <- Induction
    -> *Generic*
    ???
\end{wstructure}

Together with the type formers defined above, we would legibly expect
an elimination principle. Following a categorical intuition, we could
be tempted to provide it as a catamorphism:

\[
\F{cata} : \PITEL{\V{D}}{\Desc}
           \PI{\V{T}}{\Set}
           (\descop{\V{D}}{\V{T}} \To \V{T}) \To 
           \Mu{\V{D}} \To \V{T} 
\]

Whereas this definition is amply sufficient in the simply-typed world,
it comes short of its promises in the dependently-typed realm. Indeed,
this type is not dependent, being restricted to a notion of
\emph{iteration}. As this operator will be the corner stone of any
inductive definition, we are better off sharpening it before use.
Following \citet{benke:universe-generic-prog}, we adopt the following
definition:

\[
\begin{array}{lcll}
\F{induction} & : & \multicolumn{2}{l}{\PITEL{\V{D}}{\Desc}}                   \\
              &   & \multicolumn{2}{l}{\PITEL{\V{x}}{\Mu{\V{D}}}}                   \\
              &   & \multicolumn{2}{l}{\PITEL{\V{P}}{\Mu{\V{D}} \To \Set}}         \\
              &   & \PI{\V{m}}{& \PI{\V{xs}}{\descop{\V{D}}{(\Mu{\V{D}})}}              \\
              &   &           & \All{\V{D}}{(\Mu{\V{D}})}{\V{P}}{\V{xs}} \To \V{P} (\Con{\V{xs}})} \\
              &   & \V{P} \V{x}
\end{array}
\]

Where, intuitively, $\All{\V{D}}{\V{X}}{\V{P}}{\V{x}}$ states that
$\Bhab{\V{P}}{\V{X} \To \Set}$ holds everywhere in $\V{x}$. Its formal
definition is presented in Figure~\ref{fig:all-predicates}.  We refer
the reader to our technical report for the implementation of
$\F{induction}$. Having this dependent catamorphism, we are empowered
with the ability to $\emph{compute}$ over descriptions. Note that this
induction principle is the first manifestation of a generic operation
over descriptions. Thanks to $\F{induction}$, any datatype we define
automatically comes equipped with an induction principle.


\begin{figure*}

\[
\begin{array}{ll}
%%
\stk{
\begin{array}{@{}ll}
\All{\!}{\!}{\!}{\!} : & \PITEL{\V{D}}{\Desc}
                         \PITEL{\V{X}}{\Set}
                         \PITEL{\V{P}}{\V{X} \To \Set} \\
                       & \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
                         \Set 
\end{array} \\
\All{\DUnit}{\V{X}}{\V{P}}{\Void} = 
    \Unit \\
\All{(\DSigma{\V{S}}{\V{T}})}{\V{X}}{\V{P}}{\pair{\V{a}}{\V{b}}{}} = 
    \All{(\V{T}\: a)}{\V{X}}{\V{P}}{\V{b}} \\
\All{(\DIndx{\V{D}})}{\V{X}}{\V{P}}{\pair{\V{a}}{\V{b}}{}} =
    \TIMES{\V{P}\: \V{a}}{\All{\V{D}}{\V{X}}{\V{P}}{\V{b}}} \\
\All{(\DHindx{\V{H}}{\V{D}})}{\V{X}}{\V{P}}{\pair{\V{f}}{\V{b}}{}} =
    \TIMES{(\PI{\V{i}}{\V{H}} \V{P}\: (\V{f}\: \V{i}))}
          {\All{\V{D}}{\V{X}}{\V{P}}{\V{b}}}
}
&
%%
\stk{
\begin{array}{@{}ll}
\all{\!}{\!}{\!}{\!}{\!} : & \PITEL{\V{D}}{\Desc}
                             \PITEL{\V{X}}{\Set}
                             \PITEL{\V{P}}{\V{X} \To \Set} \\
                           & \PITEL{\V{R}}{\PI{\V{x}}{\V{X}} \V{P}\: \V{x}}
                             \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
                             \All{\V{D}}{\V{X}}{\V{P}}{\V{xs}} 
\end{array} \\
\all{\DUnit}{\V{X}}{\V{P}}{\V{R}}{\Void} =
    \Void \\
\all{(\DSigma{\V{S}}{\V{T}})}{\V{X}}{\V{P}}{\V{R}}{\pair{\V{a}}{\V{b}}{}} =
    \all{(\V{T}\: a)}{\V{X}}{\V{P}}{\V{R}}{\V{b}} \\
\all{(\DIndx{D})}{\V{X}}{\V{P}}{\V{R}}{\pair{\V{a}}{\V{b}}{}} =
    \pair{\V{R}\: \V{a}}
         {\all{\V{D}}{\V{X}}{\V{P}}{\V{R}}{\V{b}}}{} \\
\all{(\DHindx{H}{D})}{\V{X}}{\V{P}}{\V{R}}{\pair{\V{f}}{\V{b}}{}} =
    \pair{\LAM{i} \V{R}\: (\V{f}\: \V{i})}
         {\all{\V{D}}{\V{X}}{\V{P}}{\V{R}}{b}}{}
\end{array}
}
\]

\caption{Induction predicates}
\label{fig:all-predicates}

\end{figure*}


\subsection{Extending type propagation}

\begin{wstructure}
<- Extending type propagation
    <- datatype declaration turns into definitions
        -> Straightforward translation to Desc
        -> Creation of a variable referring to the structure
    <- Labelled Mu
        /> Just mention the possibility of labelling, no details required
        -> For the user, objects have names rather than Mu of codes
    <- Push Mu to an applied name [figure]
        -> Direct integration into the type propagation machinery
    -> Coded presentation is practical
        <- The user never see a code
\end{wstructure}


We have now enough machinery to build and manipulate inductive
types. In a word, we ought be able to \emph{program} over these
datatypes.  However, one could argue that programming with these
objects is not practical.

Whereas simply-typed languages feature a convenient grammar for
defining datatypes and manipulating them, our proposal could be seen
as a step backward. In our setting, the developer would have to write
a description instead of a sugared datatype definition. Then, to
recognise an element of $\Nat$ for instance, she would have to
identify $\Mu{}$ of some coded description as indeed the fix-point of
the pattern functor of natural numbers. Finally, she would have to
write codes instead of datatype constructors.

As for finite sets previously, these symptoms clearly indicate that we
suffer from too much type information. Just as for finite sets, the
cure lies in rationalising this information. Let us first tackle the
issue of datatype declaration. The grammar of datatypes we are used
to can be straightforwardly translated to the sigmas-of-sigmas
paradigm. Hence, a datatype definition can be turned into the
corresponding description. Then, at the level of definitions, we
associate the name of the datatype to the fix-point of the
description. The induction principle as well as other generic
operations follow for free.

Doing so, we seal datatype definition behind a convenient
abstraction. We take advantage of this abstraction barrier to address
the second issue. Namely, the developer would rather be presented a
name than a fix-point of a pattern functor. Surprisingly, it is
sufficient to \emph{label} the $\Mu{}$ constructor with the
user-defined name. When pretty-printing this object, we just expose
the label, instead of the definition in full.

Regaining the ability to write datatype constructors is simply a
matter of type propagation. We therefore extend the type-checking
framework of Figure~\ref{fig:type-checking} with the following
inference rule:

\[
\Rule{\propag{\push{\widetilde{\V{e}}}
                   {\descop{\V{f}\: \V{C}}{(\Mu{(\DSigma{(\Enum\: \V{b})}{\V{f}})})}}}
            {\widetilde{\V{e}}'}}
     {\propag{\push{\V{C}\: \vec{\V{e}}}
                   {\Mu{(\DSigma{(\Enum\: \V{b})}{\V{f}})}}}
             {\Con{(\etag{\V{C}}, \widetilde{\V{e}}')}}}\;\etag{\V{C}} \in \V{b}
\]

Where $\vec{\V{e}}$ denotes a telescope of arguments applied to the
constructor $\V{C}$. For the sake of readability, we write function
application in the small function space as $\V{f}\: \V{C}$. This
corresponds to a call to $\F{switch}$. Also, we note
$\widetilde{\V{e}}$ the right-nested tuple terminated by $\Void$
corresponding to the curried telescope $\vec{\V{e}}$.

Hence, in the high-level expression language, the developer writes a
familiar type constructor, applied to a telescope of arguments. During
type propagation, this expression will be pushed to a $\Mu{}$ type of
a tagged description. It is then straightforward to look-up the tag
and turn the constructor form into the appropriate code.

This concludes our presentation of the universe of descriptions. In
this section, we have seen how datatypes from the simply-typed world
can be expressed in our dependently-typed setting. By relying on a
universe construction technique, we benefit from the ability to
inspect and manipulate these codes. This opens some appealing
opportunities for generic programming. Finally, we have demonstrated
that programming with codes is practical. To this end, we have
extended the type propagation machinery. In this setting, we can
define, interact, and build datatypes as transparently as in the
simply-typed world.
