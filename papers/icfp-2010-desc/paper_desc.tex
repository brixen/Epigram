\section{A Universe of Inductive Datatypes}
\label{sec:universe-desc}

\begin{wstructure}
<- Why starting with simple datatypes
    <- For pedagogical purposes
        <- datatypes as we know them every day
        /> Target dependent types
    -> Cut down version of Induction Recursion
        -> Presentation evolves independently as we go to dependent types
\end{wstructure}

In this section, we describe an implementation of inductive types, as
we know them in ML-like languages. By working with familiar datatypes,
we hope to focus on the delivery mechanism, warming up gently to the
indexed datatypes we really want.  % Our encoding is inspired by
Dybjer and Setzer's closed formulation of
induction-recursion~\cite{dybjer:axiom-ir}, but without the
`-recursion'.  An impredicative Church-style encoding of datatypes is
not adequate for dependently typed programming, as although such
encodings present data as non-dependent eliminators, they do not
support dependent \emph{induction}~\cite{geuvers:induction-not-derivable}.
Whilst the \(\LAMBINDER\)-calculus captures all that data can \emph{do},
it cannot ultimately delimit all that data can \emph{be}.

\subsection{The power of $\Sigma$}

\begin{wstructure}
<- The duality of Sigma
    <- Sigma generalises sum over arbitrary arities
        -> \Sigma A B == \Sigma_{x : A} B x
    <- Sigma generalises product to have a dependant second component
        -> \Sigma A B == (x : A) \times (B x)
\end{wstructure}

In dependently typed languages, $\Sigma$-types can be interpreted as
two different generalisations. This duality is reflected in the
notation we can find in the literature. The notation
$\blue{\Sigma}_{\x : \M{A}} (\M{B}\: \x)$ stresses that
$\Sigma$-types are `dependent sums', generalising sums over
arbitrary arities, where simply typed languages have finite sums.

On the other hand, our choice of notation $\SIGMA{\x}{\M{A}}
(\M{B}\:\x)$ emphasises that $\Sigma$-types generalise products,
with the type of the second component depending on the value of the
first, where simply typed languages do not express such relative validity.

\begin{wstructure}
<- datatypes in the simply-typed world
    -> "sums-of-product"
        <- Sum of constructors
        <- Product of arguments
<- datatypes in the dependently-typed world
    -> "sigmas-of-sigmas"
    /> Need ability to manipulate these sigmas
        -> Define a Code for datatypes
        -> Together with a sigma-based Interpretation
\end{wstructure}

In ML-like languages, datatypes are presented as a
\emph{sum-of-products}. A datatype is defined by a finite sum of
constructors, each carrying a product of arguments. To embrace
these datatypes, we have to capture this grammar.
With dependent types, the notion of sum-of-products translates into
\emph{sigmas-of-sigmas}.


\subsection{The universe of descriptions}
\label{sec:desc-universe}

\begin{wstructure}
<- Introduction to Universe construction
    <- Define a Code
        -> Name objects
    <- Define an Interpretation of codes into the type theory
        -> Give a semantics to objects
    -> Ability to manipulate code
    -> Ability to compute with these objects
\end{wstructure}

While sigmas-of-sigmas can give a \emph{semantics} for the
sum-of-products structure in each node of the tree-like values in a
datatype, we need to account somehow for the recursive structure which
ties these nodes together. Not for the first time, we do this by
constructing a \emph{universe}~\cite{martin-lof:itt}. Universes
are ubiquitous in dependently typed
programming~\cite{benke:universe-generic-prog, oury:power-of-pi},
but here we seek to exploit them as the foundation of our notion
of datatypes.

%The key idea behind universe construction is our ability to make names
%by defining new types. These names are called \emph{codes}. By
%defining a set of codes, we define the syntax of a language. To give
%it a semantics, we \emph{interpret} these codes back into the type
%theory. Hence, codes act as labels, while the type theory provides the
%computational machinery. Codes being mere labels, we can inspect them,
%hence regaining structural information. We can also compute over them:
%deriving new codes from others, or even functions on them.

\begin{wstructure}
<- Justification of the code 
    <- [both figures]: cannot be read separately
    <- Mimic the standard grammar of datatypes description
        -> Just as we already know it
        <- '\Sigma for making sigmas-of-sigmas
        <- 'indx for exhibiting the functoriality
            -> For recursive arguments
        <- '1 for end of description
\end{wstructure}

To add inductive types to our type theory, we build a universe of
datatype \emph{descriptions} by implementing the signature presented
in Figure~\ref{fig:desc_universe}, with codes mimicking the grammar of
datatype declarations. We can read a description $\V{D}:\Desc$ as a
`pattern functor' on $\Set$, with $\SYMBdescop{\V{D}}$ its action on
an object, \(\V{X}\), soon to be instantiated recursively.

Descriptions are sequential structures, terminated by $\DUnit$, indicating
the empty tuple. To build
sigmas-of-sigmas, we define a $\SYMBDSigma$ code, interpreted as a
$\Sigma$-type. To request a recursive component, we have $\DIndx{\V{D}}$,
where \(\V{D}\) describes the rest of the node.

\begin{figure}
\[\stk{
\begin{array}{l}
\Desc : \Set\\
\DUnit : \Desc\\
\DSigma{(\Bhab{\V{S}}{\Set})}{(\Bhab{\V{D}}{\V{S} \To \Desc})} : \Desc\\
\DIndx{(\Bhab{\V{D}}{\Desc})} : \Desc \\
\end{array}
\smallskip\\
\begin{array}{l@{\V{X}\:\mapsto\:}l}     
\multicolumn{2}{l}{\descop{\_\:}{} : \Desc \To \Set \To \Set} \\
 \descop{\DUnit}{} &  \Unit \\
 \descop{\DSigma{\V{S}}{\V{D}}}{} &
     \SIGMAS{\Bhab{\V{s}}{\V{S}}}{\descop{\V{D}\,\V{s}}{\!\V{X}}}  \\
\descop{\DIndx{\V{D}}}{}  &  \TIMES{\V{X}}{\descop{\V{D}}{\V{X}}}
\end{array}
}\]

\caption{Universe of Descriptions}
\label{fig:desc_universe}
 
\end{figure}

You may have noticed that we are a little coy about this presentation,
writing of `implementing a signature' without clarifying how. A viable
approach would simply be to extend the theory with constants for the
constructors and an operator for \(\descop{\V{D}}\). However, in
Section~\ref{sec:desc-levitate}, you will see what we actually do.  In
the meantime, let us first gain some intuition for its use by
developing some examples.

\subsection{Examples}
\label{sec:desc-examples}

\begin{wstructure}
<- Nat
    <- Sum of zero, suc
    <- zero case: done
    <- suc case: leave open and done
    -> NatD Z = 1 + Z
\end{wstructure}

We begin with the natural numbers, now working in the high-level
expression language of Section~\ref{sec:type-propagation}, exploiting
type propagation.
%
\[\stk{
\NatD : \Desc \\
\NatD \mapsto \DSigma{\EnumT{\sqr{\NatZero\: \SYMBNatSuc }}}
                     {\sqr{ \DUnit \quad (\DIndx{\DUnit}) }}
}\]
%
Let us explain its construction. First, we use $\SYMBDSigma$ to
give a choice between the $\NatZero$ and $\SYMBNatSuc$ constructors.
What follows depends on this choice, so we write the function
computing the rest of the description in tuple notation.  In the
$\NatZero$ case, we reach the end of the description. In the
$\SYMBNatSuc$ case, we attach one recursive argument and close the
description. Translating the \(\Sigma\) to a binary sum, we have
effectively described the functor:
%
\[    \NatD\: \V{Z} \mapsto \Unit \mathop{\D{+}} \V{Z}    \]
Correspondingly, we can see the injections to the sum:
\[
\sqr{\NatZero}:\descop{\NatD}Z \qquad
\sqr{\NatSuc{(\Bhab{z}{Z})}}:\descop{\NatD}Z
\]

\begin{wstructure}
<- List
    <- Sum of nil, cons
    <- nil case: done
    <- cons case: product of X with leave open and done
    -> ListD X Z = 1 + X * Z
\end{wstructure}

With a small change to this definition, we obtain the pattern functor
for lists:
%
\[\stk{
\ListD : \Set \To \Desc \\
\ListD \: \V{X} \mapsto
 \DSigma{\EnumT{\sqr{ \ListNil\: \SYMBListCons }}}
         {\sqr{ \DUnit \quad (\DSigma{\V{X}}{\LAM{\_} \DIndx{\DUnit}}) }}
}\]
%
The $\SYMBNatSuc$ constructor is turned into a proper
$\SYMBListCons$, taking an argument in $\V{X}$ followed by a
recursive argument. This code describes the following functor:
%
\[    \ListD\: \V{X}\: \V{Z} \mapsto \Unit \mathop{\D{+}} \V{X} \D{\ensuremath{\times}} \V{Z}     \]

\begin{wstructure}
<- Tree
    <- sum of leaf, node
    <- leaf case: done
    <- node case: product of X with two leave open and done
    -> TreeD X Z = 1 + X * Z * Z
\end{wstructure}

Finally, we are not limited to one recursive argument. This is
demonstrated by our description of node-labelled binary trees:
%
\[\stk{
\TreeD : \Set \To \Desc \\
\begin{array}{@{}ll}
\TreeD \: \V{X} \mapsto \DSigma{ & \EnumT{\sqr{ \TreeLeaf\: \TreeNode }} \\}
  { & \sqr{ \DUnit \quad
       ( \DIndx{(\DSigma{\V{X}}{\LAM{\_}\DIndx{\DUnit}})})} }
\end{array}
}\]
%
Again, we are one evolutionary step away from $\ListD$. However,
instead of a single call to the induction code, we add another. The
interpretation of this code corresponds to the following functor:
%
\[    \TreeD\: \V{X}\: \V{Z} \mapsto \Unit \mathop{\D{+}} 
          \V{Z} \Prod \V{X}  \Prod \V{Z}     \]


\begin{wstructure}
<- Tagged description
    <- Form TDesc = List (UId x Desc) [equation]
    <- Follow usual sums-of-product presentation of datatype
        <- Finite set of constructors
        <- Then whatever you want
    -> Any Desc datatype can be turned into this form
        -> No loss of expressive power
        /> Guarantee a ``constructor form''
\end{wstructure}

From the examples above, we observe that datatypes are defined by a
$\SYMBDSigma$ whose first argument enumerates the constructors. We
call codes fitting this pattern \emph{tagged} descriptions. Again,
this is a clear reminder of the sum-of-products style. Every
description can be forced into this style with a singleton constructor
if necessary. We characterise tagged descriptions thus:
\[\stk{
 \TagDesc : \Set \\
 \TagDesc \mapsto \SIGMA{\V{E}}{\EnumU} (\spi{\V{E}}{(\LAM{\_} \Desc)})
\smallskip\\
\SYMBtoDesc : \TagDesc\To\Desc \\
\SYMBtoDesc \mapsto
\spl{\LAM{\V{E}}\LAM{\V{D}}
\DSigma{\EnumT{\V{E}}}{(\F{switch}\:\V{E}\:(\LAM{\_}\Desc)\:\V{D})}}
}\]
It is not a great stretch to imagine that the traditional datatype
declaration syntax might desugar to the \emph{definition} of a datatype
via a tagged description.

\begin{wstructure}
<- Fictive object [figure 'data Desc']
    -> Must be read as a type signature
    -> See further for its actual implementation
        <- Subject to our levitation exercise
\end{wstructure}

\subsection{The least fixpoint}
\label{sec:desc-fix-point}

\begin{wstructure}
<- Build the fixpoint of functors
    <- See examples: need to build their initial algebra
    -> Extend the type theory with Mu/Con [figure]
        <- Straightforward definition of a fixpoint
            <- Interpret D with (Mu D) as sub-objects
\end{wstructure}


So far, we have built pattern functors with our \(\Desc\) universe.
Being polynomial functors, they all admit a least fixpoint, which we
now construct by \emph{tying the knot}: the element type abstracted
by the functor is now instantiated recursively:
%
\[
\Rule{\Gamma \vdash \Bhab{\M{D}}{\Desc}}
     {\Gamma \vdash \Bhab{\Mu{\M{D}}}{\Set}} \qquad
\Rule{\Gamma \vdash \Bhab{\M{D}}{\Desc} \quad 
      \Gamma \vdash \Bhab{\M{d}}{\descop{\M{D}}{(\Mu{\M{D}})}}}
     {\Gamma \vdash \Bhab{\Con{\M{d}}}{\Mu{\M{D}}}}
\]

\begin{wstructure}
<- Elimination on Mu
    <- We are used to foldD : \forall X. (desc D X -> X) -> mu D -> X
        /> Not dependent
        -> Cannot express some (which one again?) properties
    -> Develop a dependent induction
        <- Everywhere/All
        <- Induction
    -> *Generic*
    ???
\end{wstructure}

We can now build datatypes and their elements, e.g.:
\[\stk{
\Nat\mapsto\Mu{(\toDesc{\pair{\sqr{\NatZero\: \SYMBNatSuc }}
                       {\sqr{ \DUnit \quad (\DIndx{\DUnit})}}{}})}:\Set
\\
\Con{\sqr{\NatZero}}:\Nat \qquad
\Con{\sqr{\NatSuc{(\Bhab{n}{\Nat})}}}:\Nat
}\]

But how shall we compute with our data?  We should expect an
elimination principle. Following a categorical intuition, we might
provide the `fold', or `iterator', or `catamorphism':
%
\[
\F{cata} : \PITEL{\V{D}}{\Desc}
           \PI{\V{T}}{\Set}
           (\descop{\V{D}}{\V{T}} \To \V{T}) \To 
           \Mu{\V{D}} \To \V{T} 
\]

However, iteration is inadequate for \emph{dependent} computation.
We need \emph{induction} to write functions whose type depends on inductive
data. Following \citet{benke:universe-generic-prog}, we adopt the following:
%
\[\stk{
\F{ind} : \stk{ \PITEL{\V{D}}{\Desc}
                    \PI{\V{P}}{\Mu{\V{D}} \To \Set}         \\
               (\PI{\V{d}}{\descop{\V{D}}{(\Mu{\V{D}})}}       
                \All{\V{D}}{(\Mu{\V{D}})}{\V{P}}{\V{d}} \To \V{P} (\Con{\V{d}})) \To \\
               \PI{\V{x}}{\Mu{\V{D}}} \V{P} \V{x} 
} \\
\F{ind}\, \V{D}\, \V{P}\, \V{m}\, (\Con{\V{d}}) = 
    \V{m}\, \V{d}\, (\all{\V{D}}{(\Mu{\V{D}})}{\V{P}}
                           {(\F{ind}\, \V{D}\, \V{P}\, \V{m})}
                           {\V{d}})
}\]
%
Here, $\All{\V{D}}{\V{X}}{\V{P}}{\V{d}}$ states that
$\Bhab{\V{P}}{\V{X} \To \Set}$ holds for every subobject $\V{x}:\V{X}$ in \(\V{D}\), and \(\all{\V{D}}{\V{X}}{\V{P}}{\V{p}}{\V{d}}\) is a
`dependent map', applying
some \(\Bhab{\V{p}}{\PIS{\Bhab{\x}{\V{X}}}\V{P}\,\V{x}}\) to each \(\x\)
contained in \(\V{d}\). The full
definition (including an extra case, introduced shortly) is presented in
Figure~\ref{fig:all-predicates}. Note that
\(\F{ind}\) is our first generic
operation over descriptions, albeit a hardwired operator.
Any datatype we define automatically
comes with an induction principle.

We note that the very same functors \(\SYMBdescop{\M{D}}\) also admit greatest
fixpoints, and we have indeed implemented coinductive types this way, but
that is a story for another time.

\begin{figure*}

\[
\begin{array}{ll}
%%
\stk{
\begin{array}{@{}ll}
\SYMBAll : & \PITEL{\V{D}}{\Desc}
             \PITEL{\V{X}}{\Set}
             \PITEL{\V{P}}{\V{X} \To \Set} \\
           & \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
             \Set 
\end{array} \\
\begin{array}{@{}l@{}l@{\:=\:\:}l}
\All{\DUnit}{& \V{X}}{\V{P}}{\Void} &
    \Unit \\
\All{(\DSigma{\V{S}}{\V{D}})}{& \V{X}}{\V{P}}{\pair{\V{s}}{\V{d}}{}} &
    \All{(\V{D}\: \V{s})}{\V{X}}{\V{P}}{\V{d}} \\
\All{(\DIndx{\V{D}})}{& \V{X}}{\V{P}}{\pair{\V{x}}{\V{d}}{}} &
    \TIMES{\V{P}\: \V{x}}{\All{\V{D}}{\V{X}}{\V{P}}{\V{d}}} \\
\All{(\DHindx{\V{H}}{\V{D}})}{& \V{X}}{\V{P}}{\pair{\V{f}}{\V{d}}{}} &
    \TIMES{(\PI{\V{h}}{\V{H}} \V{P}\: (\V{f}\: \V{h}))}
          {\All{\V{D}}{\V{X}}{\V{P}}{\V{d}}}
\end{array}
}
&
%%
\stk{
\begin{array}{@{}ll}
\SYMBall : & \PITEL{\V{D}}{\Desc}
             \PITEL{\V{X}}{\Set}
             \PITEL{\V{P}}{\V{X} \To \Set} \\
           & \PITEL{\V{p}}{\PI{\V{x}}{\V{X}} \V{P}\: \V{x}}
             \PI{\V{xs}}{\descop{\V{D}}{\V{X}}} 
             \All{\V{D}}{\V{X}}{\V{P}}{\V{xs}} 
\end{array} \\
\begin{array}{@{}l@{}l@{\:=\:\:}l}
\all{\DUnit}{& \V{X}}{\V{P}}{\V{p}}{\Void} &
    \Void \\
\all{(\DSigma{\V{S}}{\V{D}})}{& \V{X}}{\V{P}}{\V{p}}{\pair{\V{s}}{\V{d}}{}} &
    \all{(\V{D}\: \V{s})}{\V{X}}{\V{P}}{\V{p}}{\V{d}} \\
\all{(\DIndx{\V{D}})}{& \V{X}}{\V{P}}{\V{p}}{\pair{\V{x}}{\V{d}}{}} &
    \pair{\V{p}\: \V{x}}
         {\all{\V{D}}{\V{X}}{\V{P}}{\V{p}}{\V{d}}}{} \\
\all{(\DHindx{\V{H}}{\V{D}})}{& \V{X}}{\V{P}}{\V{p}}{\pair{\V{f}}{\V{d}}{}} &
    \pair{\LAM{\V{h}} \V{p}\: (\V{f}\: \V{h})}
         {\all{\V{D}}{\V{X}}{\V{P}}{\V{p}}{\V{d}}}{}
\end{array}
\end{array}
}
\]

\caption{Defining and collecting inductive hypotheses}
\label{fig:all-predicates}

\end{figure*}


\subsection{Extending type propagation}

\begin{wstructure}
<- Extending type propagation
    <- datatype declaration turns into definitions
        -> Straightforward translation to Desc
        -> Creation of a variable referring to the structure
    <- Labelled Mu
        /> Just mention the possibility of labelling, no details required
        -> For the user, objects have names rather than Mu of codes
    <- Push Mu to an applied name [figure]
        -> Direct integration into the type propagation machinery
    -> Coded presentation is practical
        <- The user never see a code
\end{wstructure}


We have now enough machinery to build and manipulate inductive
types at a low level. Let us now apply cosmetic surgery
to the syntactic overhead. We extend type checking of
expressions:
%
\[
\Rule{\Gamma\Vdash\propag{\push{\etag{c}}{\EnumT{\M{E}}}}{n} \quad
\Gamma\Vdash  
\propag{
  \push{\sqr{\vec{t}}}
   {\descop{\M{D}\: n}{(\Mu{(\DSigma{\EnumT{\M{E}}}{\M{D}})})}}}
        {\M{t'}}}
     {\Gamma\Vdash\propag{\push{\etag{c}\: \vec{\M{t}}}
                   {\Mu{(\DSigma{\EnumT{\M{E}}}{\M{D}})}}}
             {\Con{\pair{n}{\M{t'}}{}}}}
\]
%
Here $\etag{c}\:\vec{t}$ denotes a tag `applied' to a sequence
of arguments, and \(\sqr{\vec{t}}\) that sequence's repackaging as
a right-nested tuple. Now we can just write data directly.
\[
\NatZero:\Nat\qquad \NatSuc{(\Bhab{n}{\Nat})}:\Nat
\]
Once again, the type explains the legible presentation, as well as
the low-level representation.

We may also simplify appeals to induction by type propagation, as we
have done with functions from pairs and enumerations.
\[
\Rule{\Gamma\Vdash\stk{
\propag{\push{\M{f}}
             {\PI{\V{d}}{\descop{\M{D}}{(\Mu{\M{D}})}}       
                \All{\M{D}}{(\Mu{\M{D}})}{(\PLAM{\x}{\Mu{\M{D}}}\M{P})}{\V{d}} \To \M{P}[\Con{\V{d}}/\x]\\}}
       {\M{f'}}}}
{\Gamma\Vdash
\propag{\push{\sind{\M{f}}}
             {\PIS{\Bhab{\x}{\Mu{\M{D}}}}\M{P} }}
       {\F{ind}\:\M{D}\:(\PLAM{\x}{\Mu{\M{D}}}\M{P})\:\M{f'}}}
\]
This abbreviation is no substitute for the dependent pattern
matching to which we are entitled in a high-level language built on top
of this theory~\cite{goguen:pattern-matching}, but it does at least make
`assembly language' programming mercifully brief, if hieroglyphic.
\[\stk{
\F{plus}:\Nat\To\Nat\To\Nat \\
\F{plus}\mapsto\sind{\spl{\sqr{(\LAM{\_}\LAM{\_}\LAM{\V{y}}\V{y})
  \quad(\LAM{\_}\spl{\LAM{\V{h}}\LAM{\_}\LAM{\V{y}}
    \NatSuc{(\V{h}\:\V{y})}})}}}
}\]

This concludes our introduction to the universe of datatype descriptions.
We have encoded sum-of-products datatypes from the simply-typed world
as data and equipped them with computation. We have also made sure
to hide the details by type propagation.
